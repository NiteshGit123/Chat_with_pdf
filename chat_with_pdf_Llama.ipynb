{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "65b358f7355e479199d008b7fccf40d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d33d0f0a61a243c2882d222cddfc6732",
              "IPY_MODEL_c679cac6e61c4289b81560dc3fc66c20",
              "IPY_MODEL_169fde6b280241098d28c45685be1805"
            ],
            "layout": "IPY_MODEL_20341f667aed49f8943697da2729ee0b"
          }
        },
        "d33d0f0a61a243c2882d222cddfc6732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a01ccf2bb5754d2390e88b9e21aa25cf",
            "placeholder": "​",
            "style": "IPY_MODEL_db1fa26730ec400a8d2aff032ca08f5a",
            "value": "modules.json: 100%"
          }
        },
        "c679cac6e61c4289b81560dc3fc66c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0c35d82a2f649b2863c9b83e1949340",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28628ccd19fa4016834f9e61cc137d8e",
            "value": 349
          }
        },
        "169fde6b280241098d28c45685be1805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b339c7a962d429c9f6eab7239324a0e",
            "placeholder": "​",
            "style": "IPY_MODEL_ed4bb05a2a6747adb50df234ae04df79",
            "value": " 349/349 [00:00&lt;00:00, 17.5kB/s]"
          }
        },
        "20341f667aed49f8943697da2729ee0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a01ccf2bb5754d2390e88b9e21aa25cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db1fa26730ec400a8d2aff032ca08f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0c35d82a2f649b2863c9b83e1949340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28628ccd19fa4016834f9e61cc137d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b339c7a962d429c9f6eab7239324a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed4bb05a2a6747adb50df234ae04df79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0221851a2a224f1faeebc68319dc1c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84a5174c6fab48a7b8d1353328a1e6b9",
              "IPY_MODEL_78fe88dfaf524bbf8fbae7ba6fd62df0",
              "IPY_MODEL_5504a3838bc74d2c85d8fc1fe2a6054e"
            ],
            "layout": "IPY_MODEL_b623189b0191471087df68fa96695db9"
          }
        },
        "84a5174c6fab48a7b8d1353328a1e6b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b09f062f7ae242cdb7b548cd8c5e1d01",
            "placeholder": "​",
            "style": "IPY_MODEL_282d6dffdff448eb93282b5561a01b32",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "78fe88dfaf524bbf8fbae7ba6fd62df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd3b6d6b2866450489d73e0df990b979",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7aabca8ac9f45e486a7c00ef07742f1",
            "value": 116
          }
        },
        "5504a3838bc74d2c85d8fc1fe2a6054e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c622b1ec8664a15a999b33c1d2ba95a",
            "placeholder": "​",
            "style": "IPY_MODEL_04f44a1d74c74358b71aa1433deadd9a",
            "value": " 116/116 [00:00&lt;00:00, 8.52kB/s]"
          }
        },
        "b623189b0191471087df68fa96695db9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b09f062f7ae242cdb7b548cd8c5e1d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "282d6dffdff448eb93282b5561a01b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd3b6d6b2866450489d73e0df990b979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7aabca8ac9f45e486a7c00ef07742f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c622b1ec8664a15a999b33c1d2ba95a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04f44a1d74c74358b71aa1433deadd9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c44c73bf6c56491fb52e411817c68ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adf38f5ac91642869da939843e33eb85",
              "IPY_MODEL_fee64dcf825f4782abe3312d389b98a9",
              "IPY_MODEL_2607247ce083405e84e1a0c0b621992d"
            ],
            "layout": "IPY_MODEL_6861d1f131554f7a9c28c673a75b9924"
          }
        },
        "adf38f5ac91642869da939843e33eb85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5952cba1275345eeaa2f1f7ef2a69fca",
            "placeholder": "​",
            "style": "IPY_MODEL_8ae46e617df8460288bd81ec2fcb386e",
            "value": "README.md: 100%"
          }
        },
        "fee64dcf825f4782abe3312d389b98a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d09e66b6b86c46efb9b37d24df9434f8",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7caff54ac3504713969586a0e7594764",
            "value": 10659
          }
        },
        "2607247ce083405e84e1a0c0b621992d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5001e02e5153482e9b7382aa7b0b026c",
            "placeholder": "​",
            "style": "IPY_MODEL_ff9030a329d14f7a9e174ee3f2cde6a6",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 728kB/s]"
          }
        },
        "6861d1f131554f7a9c28c673a75b9924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5952cba1275345eeaa2f1f7ef2a69fca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae46e617df8460288bd81ec2fcb386e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d09e66b6b86c46efb9b37d24df9434f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7caff54ac3504713969586a0e7594764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5001e02e5153482e9b7382aa7b0b026c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff9030a329d14f7a9e174ee3f2cde6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "582e610b38c3402faca432105fb5712a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f81caa54ab74430cbddf9caf52b34534",
              "IPY_MODEL_932be7d3dbcd46cfa72fa7d11c4d6343",
              "IPY_MODEL_fdf009e9bc66449b8d41b8693efcbf5f"
            ],
            "layout": "IPY_MODEL_a9e4b0e4f1534036951a15909a9046da"
          }
        },
        "f81caa54ab74430cbddf9caf52b34534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cb554a5bdef4f48937ab3e4219e7864",
            "placeholder": "​",
            "style": "IPY_MODEL_7a97a99e686e49bf8fc2d51a4428b29e",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "932be7d3dbcd46cfa72fa7d11c4d6343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04f39585638c46d6b921bc1ef71e1d2d",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72ef9874d1464de7a4260eec342259e8",
            "value": 53
          }
        },
        "fdf009e9bc66449b8d41b8693efcbf5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a082253244aa4008a42d9431dac785c0",
            "placeholder": "​",
            "style": "IPY_MODEL_c8d6f69ad85b4a218ea7841f44ee928e",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.18kB/s]"
          }
        },
        "a9e4b0e4f1534036951a15909a9046da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cb554a5bdef4f48937ab3e4219e7864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a97a99e686e49bf8fc2d51a4428b29e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04f39585638c46d6b921bc1ef71e1d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72ef9874d1464de7a4260eec342259e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a082253244aa4008a42d9431dac785c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8d6f69ad85b4a218ea7841f44ee928e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25d43ba9f75047c19ccbb994e646bd97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63e79626f8c84b8bb31c37a5b2474812",
              "IPY_MODEL_add720e2551e4ddb9e047d3e02dc3ba7",
              "IPY_MODEL_bf1b25103e8045ebbf8ef4bab1da0dbb"
            ],
            "layout": "IPY_MODEL_13b51f2be44541b2bb43a943ff4e4b21"
          }
        },
        "63e79626f8c84b8bb31c37a5b2474812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ed6da40c8f24404be9c2ad58a00d95a",
            "placeholder": "​",
            "style": "IPY_MODEL_c89d6a29aa6d4cd48d327905f6cd2060",
            "value": "config.json: 100%"
          }
        },
        "add720e2551e4ddb9e047d3e02dc3ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18e081b4cdfe4c58a36a5af3f72d9e25",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b10e789392894253831984c5ff327dc2",
            "value": 612
          }
        },
        "bf1b25103e8045ebbf8ef4bab1da0dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fda11be261de4550a3b514e057b3e99d",
            "placeholder": "​",
            "style": "IPY_MODEL_8fb98ef096974fdd864fa56db42d3730",
            "value": " 612/612 [00:00&lt;00:00, 40.1kB/s]"
          }
        },
        "13b51f2be44541b2bb43a943ff4e4b21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ed6da40c8f24404be9c2ad58a00d95a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c89d6a29aa6d4cd48d327905f6cd2060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18e081b4cdfe4c58a36a5af3f72d9e25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b10e789392894253831984c5ff327dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fda11be261de4550a3b514e057b3e99d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fb98ef096974fdd864fa56db42d3730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d39942ee213849409e6992888d029e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b936bc30dddd4f86944a1a1ea70152ff",
              "IPY_MODEL_d46730d42da14f818639f913f8fb915e",
              "IPY_MODEL_1c12f8bf01a3421380b888a429d4535b"
            ],
            "layout": "IPY_MODEL_bd8ef83e3b2d4793a2976410c475cedc"
          }
        },
        "b936bc30dddd4f86944a1a1ea70152ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0043e51038794784995fb018ba124b95",
            "placeholder": "​",
            "style": "IPY_MODEL_1acb1ef952d7411fa5187c455d38b3a7",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "d46730d42da14f818639f913f8fb915e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6d7161a7b6c4cacadfa97cac0189e39",
            "max": 90888945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1acdeebee00a42fd9ceecda71dd8a19b",
            "value": 90888945
          }
        },
        "1c12f8bf01a3421380b888a429d4535b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ef43f669829492b9eb86c0114e8393f",
            "placeholder": "​",
            "style": "IPY_MODEL_afe9d4891f1046e8905d6acc6f83229b",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 283MB/s]"
          }
        },
        "bd8ef83e3b2d4793a2976410c475cedc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0043e51038794784995fb018ba124b95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1acb1ef952d7411fa5187c455d38b3a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6d7161a7b6c4cacadfa97cac0189e39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1acdeebee00a42fd9ceecda71dd8a19b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ef43f669829492b9eb86c0114e8393f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afe9d4891f1046e8905d6acc6f83229b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5448d3d34fa2476986d968b9bd38cc57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d830211330cf4c3fae49d62953e7dcc0",
              "IPY_MODEL_3c5c2b48efb94f9da1051a819d8ee386",
              "IPY_MODEL_f80f6e77ebc445c799d66aebdff2e90d"
            ],
            "layout": "IPY_MODEL_73570070008244e89f16ded503a45153"
          }
        },
        "d830211330cf4c3fae49d62953e7dcc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d393d3ef4aed4b35a10dd2cfe54f0725",
            "placeholder": "​",
            "style": "IPY_MODEL_d9aeb9d9f93e4571a864c1ac73f0c037",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3c5c2b48efb94f9da1051a819d8ee386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6730cd11be04aeb830c4be895ac8723",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa9f43f5a22a43d082f2a115c82cf484",
            "value": 350
          }
        },
        "f80f6e77ebc445c799d66aebdff2e90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f4eb85b2a804209ad5ae5da382a37a6",
            "placeholder": "​",
            "style": "IPY_MODEL_bc5c1f75031642248519eff14c0acd93",
            "value": " 350/350 [00:00&lt;00:00, 24.6kB/s]"
          }
        },
        "73570070008244e89f16ded503a45153": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d393d3ef4aed4b35a10dd2cfe54f0725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9aeb9d9f93e4571a864c1ac73f0c037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6730cd11be04aeb830c4be895ac8723": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa9f43f5a22a43d082f2a115c82cf484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f4eb85b2a804209ad5ae5da382a37a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc5c1f75031642248519eff14c0acd93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fdee25b75d44949b60babfc27787b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fd8c24b1aa943d9a418f3d6f55461f5",
              "IPY_MODEL_feace6e6b92247b4bae51f177a66116b",
              "IPY_MODEL_668415a1f7eb43829fce1adaa79d5f52"
            ],
            "layout": "IPY_MODEL_d61a949b3afb4289a8b9cae64c12d363"
          }
        },
        "2fd8c24b1aa943d9a418f3d6f55461f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecc64df45cbd42558f8da8b2bf3f3058",
            "placeholder": "​",
            "style": "IPY_MODEL_651060d70ff4462ea16287a34675adae",
            "value": "vocab.txt: 100%"
          }
        },
        "feace6e6b92247b4bae51f177a66116b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5817d4dda9041d78a4f7ac17860d480",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6d15e718f96401bac06feb8b71b3cef",
            "value": 231508
          }
        },
        "668415a1f7eb43829fce1adaa79d5f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dffb5c8660ba44c6a4a6e8edfd43ed5e",
            "placeholder": "​",
            "style": "IPY_MODEL_7e7c556e75d4407493bb75014e21af0a",
            "value": " 232k/232k [00:00&lt;00:00, 461kB/s]"
          }
        },
        "d61a949b3afb4289a8b9cae64c12d363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecc64df45cbd42558f8da8b2bf3f3058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "651060d70ff4462ea16287a34675adae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5817d4dda9041d78a4f7ac17860d480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6d15e718f96401bac06feb8b71b3cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dffb5c8660ba44c6a4a6e8edfd43ed5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e7c556e75d4407493bb75014e21af0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab2d7b4f21de4592b23d869b933c6cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ada3828a18746f893ccdc2e3f5efb49",
              "IPY_MODEL_5e22719e87d64288aab5b8c4ae61f9bc",
              "IPY_MODEL_b6fb4a1acae640af97030fe0592b3809"
            ],
            "layout": "IPY_MODEL_85bf9c1acdd14fe0a02e6c1ceea0baec"
          }
        },
        "3ada3828a18746f893ccdc2e3f5efb49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9132e3fa0c044c89416f06530209420",
            "placeholder": "​",
            "style": "IPY_MODEL_6cfa8ab66dcc433f904335fd836cbe81",
            "value": "tokenizer.json: 100%"
          }
        },
        "5e22719e87d64288aab5b8c4ae61f9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0d7ca3634054e1dab9c6589bc30c048",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b85b30dcada045cd9e586b45a899b429",
            "value": 466247
          }
        },
        "b6fb4a1acae640af97030fe0592b3809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8abaf9377774ae3858b66848c32eb0f",
            "placeholder": "​",
            "style": "IPY_MODEL_18af0940cff240a8b4192502b64515de",
            "value": " 466k/466k [00:00&lt;00:00, 958kB/s]"
          }
        },
        "85bf9c1acdd14fe0a02e6c1ceea0baec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9132e3fa0c044c89416f06530209420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cfa8ab66dcc433f904335fd836cbe81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0d7ca3634054e1dab9c6589bc30c048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b85b30dcada045cd9e586b45a899b429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8abaf9377774ae3858b66848c32eb0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18af0940cff240a8b4192502b64515de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98de905ecc1e4b0680ee0a6acba981c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4fcd2200a0474eab886a3f5f27a57d54",
              "IPY_MODEL_e67b6256deca4a3aa4d7c8a8534b7016",
              "IPY_MODEL_3e813da9edcc4dba922f826fad6a029d"
            ],
            "layout": "IPY_MODEL_bdb2ddc2ebc147c7a5ab40dba7d836f6"
          }
        },
        "4fcd2200a0474eab886a3f5f27a57d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1111bcdd2a4649de830fd5d8abdf63ec",
            "placeholder": "​",
            "style": "IPY_MODEL_a9a65ea1392c4c1e927fdeda216e4ef2",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e67b6256deca4a3aa4d7c8a8534b7016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0defddce5e1a43fba8c940ee3195e5c3",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4721d3b2b4eb4e509711e006315dc937",
            "value": 112
          }
        },
        "3e813da9edcc4dba922f826fad6a029d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e8331cd56b34a2b89a9e64191e60043",
            "placeholder": "​",
            "style": "IPY_MODEL_5c301d90ca6c46d4a70150150d0874ea",
            "value": " 112/112 [00:00&lt;00:00, 8.23kB/s]"
          }
        },
        "bdb2ddc2ebc147c7a5ab40dba7d836f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1111bcdd2a4649de830fd5d8abdf63ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9a65ea1392c4c1e927fdeda216e4ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0defddce5e1a43fba8c940ee3195e5c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4721d3b2b4eb4e509711e006315dc937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e8331cd56b34a2b89a9e64191e60043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c301d90ca6c46d4a70150150d0874ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b81785468c91433499e08e85ed4877af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_069d1d2d09694f81bb852d2e25db6937",
              "IPY_MODEL_4599932db48b46fab51d36fa6e7a35a5",
              "IPY_MODEL_069e6f1b25dc4be5a152d0929febdbff"
            ],
            "layout": "IPY_MODEL_cde0a7f4d3884773a40dbca73e7ce678"
          }
        },
        "069d1d2d09694f81bb852d2e25db6937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_667879cfbf4c4a8781fdc6f8c7eebc5a",
            "placeholder": "​",
            "style": "IPY_MODEL_d7529fcf5a3f4db8a06750723cd062d0",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "4599932db48b46fab51d36fa6e7a35a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c7c173b84904335b066663d6fe2f783",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c12e3b08eeb3474894a548e8df268d39",
            "value": 190
          }
        },
        "069e6f1b25dc4be5a152d0929febdbff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7ee3de1ee1246b5b2977c8e7273c309",
            "placeholder": "​",
            "style": "IPY_MODEL_95b0a3593bb34066a3261bf85e34abb0",
            "value": " 190/190 [00:00&lt;00:00, 9.51kB/s]"
          }
        },
        "cde0a7f4d3884773a40dbca73e7ce678": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "667879cfbf4c4a8781fdc6f8c7eebc5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7529fcf5a3f4db8a06750723cd062d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c7c173b84904335b066663d6fe2f783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c12e3b08eeb3474894a548e8df268d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7ee3de1ee1246b5b2977c8e7273c309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95b0a3593bb34066a3261bf85e34abb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "caca04f9aeb3497890dcb156e73ac071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02ecffa91dfc49a09ceac96194746d3c",
              "IPY_MODEL_6fdd2e07364e48e38078fdc10df0273c",
              "IPY_MODEL_8da5653096a54114946a7e64465c1c27"
            ],
            "layout": "IPY_MODEL_7d358a3b8ccd4507b6568c83a6c619c2"
          }
        },
        "02ecffa91dfc49a09ceac96194746d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d18dc9723fa490f891404591324c467",
            "placeholder": "​",
            "style": "IPY_MODEL_9cbea59a576a43dda004e209e4536147",
            "value": "codellama-13b-python.Q5_K_M.gguf: 100%"
          }
        },
        "6fdd2e07364e48e38078fdc10df0273c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccef05d3f9d34bb2b1439b3a181e5ac3",
            "max": 9229924288,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae7a384b860b45faa49fe9fa698b977d",
            "value": 9229924288
          }
        },
        "8da5653096a54114946a7e64465c1c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2906a44937a746b7b7d5b88a20a4acbc",
            "placeholder": "​",
            "style": "IPY_MODEL_c6310166cb724e219ce95ecacad592f9",
            "value": " 9.23G/9.23G [35:47&lt;00:00, 7.11MB/s]"
          }
        },
        "7d358a3b8ccd4507b6568c83a6c619c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d18dc9723fa490f891404591324c467": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cbea59a576a43dda004e209e4536147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccef05d3f9d34bb2b1439b3a181e5ac3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae7a384b860b45faa49fe9fa698b977d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2906a44937a746b7b7d5b88a20a4acbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6310166cb724e219ce95ecacad592f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Llama 2+ Pinecone + LangChain**"
      ],
      "metadata": {
        "id": "7I2wTiMSu3PB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 1: Install All the Required Pakages**"
      ],
      "metadata": {
        "id": "udUBTNuQXOpZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_aEfiWhkWBHt",
        "outputId": "8e6c80dc-f1a7-4fa1-9dc9-a20b44c04a26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n",
            "  Downloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.31-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (3.7.1)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.33 langchain-text-splitters-0.0.1 langsmith-0.1.31 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.1.0\n",
            "Collecting unstructured\n",
            "  Downloading unstructured-0.12.6-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff==2.2.1 (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: beautifulsoup4==4.12.3 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
            "Requirement already satisfied: certifi==2024.2.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2024.2.2)\n",
            "Requirement already satisfied: chardet==5.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.3.2)\n",
            "Requirement already satisfied: click==8.1.7 in /usr/local/lib/python3.10/dist-packages (from unstructured) (8.1.7)\n",
            "Requirement already satisfied: dataclasses-json==0.6.4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.4)\n",
            "Collecting dataclasses-json-speakeasy==0.5.11 (from unstructured)\n",
            "  Downloading dataclasses_json_speakeasy-0.5.11-py3-none-any.whl (28 kB)\n",
            "Collecting emoji==2.10.1 (from unstructured)\n",
            "  Downloading emoji-2.10.1-py2.py3-none-any.whl (421 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filetype==1.2.0 (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: idna==3.6 in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.6)\n",
            "Requirement already satisfied: joblib==1.3.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.3.2)\n",
            "Collecting jsonpath-python==1.0.6 (from unstructured)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Collecting langdetect==1.0.9 (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lxml==5.1.0 (from unstructured)\n",
            "  Downloading lxml-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow==3.20.2 (from unstructured)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mypy-extensions==1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.0)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Collecting numpy==1.26.4 (from unstructured)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging==23.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (23.2)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.8.2)\n",
            "Collecting python-iso639==2024.2.7 (from unstructured)\n",
            "  Downloading python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic==0.4.27 (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Collecting rapidfuzz==3.6.1 (from unstructured)\n",
            "  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex==2023.12.25 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2023.12.25)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.31.0)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.16.0)\n",
            "Requirement already satisfied: soupsieve==2.5 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.5)\n",
            "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: tqdm==4.66.2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.66.2)\n",
            "Collecting typing-extensions==4.9.0 (from unstructured)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: typing-inspect==0.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Collecting unstructured-client==0.18.0 (from unstructured)\n",
            "  Downloading unstructured_client-0.18.0-py3-none-any.whl (21 kB)\n",
            "Collecting urllib3==1.26.18 (from unstructured)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrapt==1.16.0 (from unstructured)\n",
            "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=1b2c1115951083077e9f12446aca377a9572c41401778b609c68ca89cd4758a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, wrapt, urllib3, typing-extensions, rapidfuzz, python-magic, python-iso639, numpy, marshmallow, lxml, langdetect, jsonpath-python, emoji, backoff, dataclasses-json-speakeasy, unstructured-client, unstructured\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.10.0\n",
            "    Uninstalling typing_extensions-4.10.0:\n",
            "      Successfully uninstalled typing_extensions-4.10.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: marshmallow\n",
            "    Found existing installation: marshmallow 3.21.1\n",
            "    Uninstalling marshmallow-3.21.1:\n",
            "      Successfully uninstalled marshmallow-3.21.1\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.9.4\n",
            "    Uninstalling lxml-4.9.4:\n",
            "      Successfully uninstalled lxml-4.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.2.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "tensorflow 2.15.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.16.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 dataclasses-json-speakeasy-0.5.11 emoji-2.10.1 filetype-1.2.0 jsonpath-python-1.0.6 langdetect-1.0.9 lxml-5.1.0 marshmallow-3.20.2 numpy-1.26.4 python-iso639-2024.2.7 python-magic-0.4.27 rapidfuzz-3.6.1 typing-extensions-4.9.0 unstructured-0.12.6 unstructured-client-0.18.0 urllib3-1.26.18 wrapt-1.16.0\n",
            "Collecting numpy==1.22.4\n",
            "  Downloading numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.22.4 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
            "tensorflow 2.15.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.16.0 which is incompatible.\n",
            "unstructured 0.12.6 requires numpy==1.26.4, but you have numpy 1.22.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.22.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "2f352913151949ce8d938d2bbeea4c81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.6.0-py3-none-any.whl (163 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/163.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.1/163.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.0/731.7 MB\u001b[0m \u001b[31m172.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[2KTraceback (most recent call last):\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in \n",
            "exc_logging_wrapper\n",
            "\u001b[2K    status = run_func(*args)\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in \n",
            "wrapper\n",
            "\u001b[2K    return func(self, options, args)\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "\u001b[2K    requirement_set = resolver.resolve(\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", \n",
            "line 92, in resolve\n",
            "\u001b[2K    result = self._result = resolver.resolve(\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in \n",
            "resolve\n",
            "\u001b[2K    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 427, in \n",
            "resolve\n",
            "\u001b[2K    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 239, in \n",
            "_attempt_to_pin_criterion\n",
            "\u001b[2K    criteria = self._get_updated_criteria(candidate)\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 230, in \n",
            "_get_updated_criteria\n",
            "\u001b[2K    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 173, in \n",
            "_add_to_criteria\n",
            "\u001b[2K    if not criterion.candidates:\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/structs.py\", line 156, in \n",
            "__bool__\n",
            "\u001b[2K    return bool(self._sequence)\n",
            "\u001b[2K  File \n",
            "\"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", \n",
            "line 155, in __bool__\n",
            "\u001b[2K    return any(self)\n",
            "\u001b[2K  File \n",
            "\"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", \n",
            "line 143, in <genexpr>\n",
            "\u001b[2K    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "\u001b[2K  File \n",
            "\"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", \n",
            "line 47, in _iter_built\n",
            "\u001b[2K    candidate = func()\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", \n",
            "line 206, in _make_candidate_from_link\n",
            "\u001b[2K    self._link_candidate_cache[link] = LinkCandidate(\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", \n",
            "line 293, in __init__\n",
            "\u001b[2K    super().__init__(\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", \n",
            "line 156, in __init__\n",
            "\u001b[2K    self.dist = self._prepare()\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", \n",
            "line 225, in _prepare\n",
            "\u001b[2K    dist = self._prepare_distribution()\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", \n",
            "line 304, in _prepare_distribution\n",
            "\u001b[2K    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 516, in \n",
            "prepare_linked_requirement\n",
            "\u001b[2K    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 587, in \n",
            "_prepare_linked_requirement\n",
            "\u001b[2K    local_file = unpack_url(\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 166, in \n",
            "unpack_url\n",
            "\u001b[2K    file = get_http_url(\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 107, in \n",
            "get_http_url\n",
            "\u001b[2K    from_path, content_type = download(link, temp_dir.path)\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/network/download.py\", line 148, in \n",
            "__call__\n",
            "\u001b[2K    content_file.write(chunk)\n",
            "\u001b[2KKeyboardInterrupt\n",
            "\u001b[2K\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\u001b[2KTraceback (most recent call last):\n",
            "\u001b[2K  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "\u001b[2K    sys.exit(main())\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "\u001b[2K    return command.main(cmd_args)\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in \n",
            "main\n",
            "\u001b[2K    return self._main(args)\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in \n",
            "_main\n",
            "\u001b[2K    return run(options, args)\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in \n",
            "exc_logging_wrapper\n",
            "\u001b[2K    logger.critical(\"Operation cancelled by user\")\n",
            "\u001b[2K  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "\u001b[2K    self._log(CRITICAL, msg, args, **kwargs)\n",
            "\u001b[2K  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "\u001b[2K    self.handle(record)\n",
            "\u001b[2K  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "\u001b[2K    self.callHandlers(record)\n",
            "\u001b[2K  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "\u001b[2K    hdlr.handle(record)\n",
            "\u001b[2K  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "\u001b[2K    self.emit(record)\n",
            "\u001b[2K  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "\u001b[2K    logging.FileHandler.emit(self, record)\n",
            "\u001b[2K  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "\u001b[2K    StreamHandler.emit(self, record)\n",
            "\u001b[2K  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "\u001b[2K    msg = self.format(record)\n",
            "\u001b[2K  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "\u001b[2K    return fmt.format(record)\n",
            "\u001b[2K  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 118, in format\n",
            "\u001b[2K    prefix = f\"{self.formatTime(record)} \"\n",
            "\u001b[2K  File \"/usr/lib/python3.10/logging/__init__.py\", line 597, in formatTime\n",
            "\u001b[2K    def formatTime(self, record, datefmt=None):\n",
            "\u001b[2KKeyboardInterrupt\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.2/731.7 MB\u001b[0m \u001b[31m164.7 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
            "\u001b[?25h^C\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-3.2.0-py3-none-any.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.2.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.26.18)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install unstructured\n",
        "!pip install numpy==1.22.4\n",
        "!pip install sentence_transformers\n",
        "!pip install pinecone-client\n",
        "!pip install llama-cpp-python\n",
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 2: Import All the Required Libraries**"
      ],
      "metadata": {
        "id": "Logc48CDXirQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy 1.26.4 is giving some issues\n",
        "!pip install numpy==1.22.4\n",
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdrmphZFKpMj",
        "outputId": "7af5f00c-d8db-4d5f-b700-e257d43367fc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.22.4 in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Collecting sentence_transformers\n",
            "  Using cached sentence_transformers-2.6.0-py3-none-any.whl (163 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 sentence_transformers-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone-client\n",
        "!pip install llama-cpp-python\n",
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wct2rFkSfVwF",
        "outputId": "d055e50d-f397-444b-8f12-11ba0baa9f87"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.2.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.26.18)\n",
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.57.tar.gz (36.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.9/36.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.9.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.22.4)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.57-cp310-cp310-manylinux_2_35_x86_64.whl size=2872751 sha256=07dcacac1a7117feed2b6b76337ef5cb44361084b5acfc9501c6393bb5f467d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/c0/00/e98d6e198f941c623da37b3f674354cbdccfcfb2cb9cf1133d\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.57\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader, OnlinePDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "import pinecone\n",
        "import os"
      ],
      "metadata": {
        "id": "kmdLCsZPXqwF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 3: Load the Data**"
      ],
      "metadata": {
        "id": "qBSwg7bOYCD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"https://drive.google.com/uc?id=15hUEJQViQDxu_fnJeO_Og1hGqykCmJut&confirm=t\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmrkINXzmBZj",
        "outputId": "b9c58cf8-e5f7-4a98-e2dc-d0edb42b8402"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15hUEJQViQDxu_fnJeO_Og1hGqykCmJut&confirm=t\n",
            "To: /content/The-Field-Guide-to-Data-Science.pdf\n",
            "100% 30.3M/30.3M [00:00<00:00, 56.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loader = OnlinePDFLoader(\"https://wolfpaulus.com/wp-content/uploads/2017/05/field-guide-to-data-science.pdf\")\n",
        "loader = PyPDFLoader(\"/content/5.pdf\")\n",
        "#loader = PyPDFLoader(\"/content/The-Field-Guide-to-Data-Science.pdf\")"
      ],
      "metadata": {
        "id": "Wap-CQGCXah3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = loader.load()"
      ],
      "metadata": {
        "id": "Qv6XhgnPYOKn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOgHFZsvf0jV",
        "outputId": "25520e04-9ff8-4e96-e7eb-a7c39eb21471"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright ©2023. All\\nrights reserved. Draft of February 3, 2024.\\nCHAPTER\\n5Logistic Regression\\n“And how do you know that these ﬁne begonias are not of equal importance?”\\nHercule Poirot, in Agatha Christie’s The Mysterious Affair at Styles\\nDetective stories are as littered with clues as texts are with words. Yet for the\\npoor reader it can be challenging to know how to weigh the author’s clues in order\\nto make the crucial classiﬁcation task: deciding whodunnit.\\nIn this chapter we introduce an algorithm that is admirably suited for discovering\\nthe link between features or cues and some particular outcome: logistic regression .logistic\\nregression\\nIndeed, logistic regression is one of the most important analytic tools in the social\\nand natural sciences. In natural language processing, logistic regression is the base-\\nline supervised machine learning algorithm for classiﬁcation, and also has a very\\nclose relationship with neural networks. As we will see in Chapter 7, a neural net-\\nwork can be viewed as a series of logistic regression classiﬁers stacked on top of\\neach other. Thus the classiﬁcation and machine learning techniques introduced here\\nwill play an important role throughout the book.\\nLogistic regression can be used to classify an observation into one of two classes\\n(like ‘positive sentiment’ and ‘negative sentiment’), or into one of many classes.\\nBecause the mathematics for the two-class case is simpler, we’ll describe this special\\ncase of logistic regression ﬁrst in the next few sections, and then brieﬂy summarize\\nthe use of multinomial logistic regression for more than two classes in Section 5.3.\\nWe’ll introduce the mathematics of logistic regression in the next few sections.\\nBut let’s begin with some high-level issues.\\nGenerative and Discriminative Classiﬁers: The most important difference be-\\ntween naive Bayes and logistic regression is that logistic regression is a discrimina-\\ntiveclassiﬁer while naive Bayes is a generative classiﬁer.\\nThese are two very different frameworks for how\\nto build a machine learning model. Consider a visual\\nmetaphor: imagine we’re trying to distinguish dog\\nimages from cat images. A generative model would\\nhave the goal of understanding what dogs look like\\nand what cats look like. You might literally ask such\\na model to ‘generate’, i.e., draw, a dog. Given a test\\nimage, the system then asks whether it’s the cat model or the dog model that better\\nﬁts (is less surprised by) the image, and chooses that as its label.\\nA discriminative model, by contrast, is only try-\\ning to learn to distinguish the classes (perhaps with-\\nout learning much about them). So maybe all the\\ndogs in the training data are wearing collars and the\\ncats aren’t. If that one feature neatly separates the\\nclasses, the model is satisﬁed. If you ask such a\\nmodel what it knows about cats all it can say is that\\nthey don’t wear collars.', metadata={'source': '/content/5.pdf', 'page': 0}),\n",
              " Document(page_content='2CHAPTER 5 • L OGISTIC REGRESSION\\nMore formally, recall that the naive Bayes assigns a class cto a document dnot\\nby directly computing P(c|d)but by computing a likelihood and a prior\\nˆc=argmax\\nc∈Clikelihood\\ued17\\ued1a\\ued19\\ued18\\nP(d|c)prior\\ued17\\ued1a\\ued19\\ued18\\nP(c) (5.1)\\nAgenerative model like naive Bayes makes use of this likelihood term, whichgenerative\\nmodel\\nexpresses how to generate the features of a document if we knew it was of class c .\\nBy contrast a discriminative model in this text categorization scenario attemptsdiscriminative\\nmodel\\ntodirectly compute P(c|d). Perhaps it will learn to assign a high weight to document\\nfeatures that directly improve its ability to discriminate between possible classes,\\neven if it couldn’t generate an example of one of the classes.\\nComponents of a probabilistic machine learning classiﬁer: Like naive Bayes,\\nlogistic regression is a probabilistic classiﬁer that makes use of supervised machine\\nlearning. Machine learning classiﬁers require a training corpus of minput/output\\npairs(x(i),y(i)). (We’ll use superscripts in parentheses to refer to individual instances\\nin the training set—for sentiment classiﬁcation each instance might be an individual\\ndocument to be classiﬁed.) A machine learning system for classiﬁcation then has\\nfour components:\\n1. A feature representation of the input. For each input observation x(i), this\\nwill be a vector of features [x1,x2,...,xn]. We will generally refer to feature\\nifor input x(j)asx(j)\\ni, sometimes simpliﬁed as xi, but we will also see the\\nnotation fi,fi(x), or, for multiclass classiﬁcation, fi(c,x).\\n2. A classiﬁcation function that computes ˆ y, the estimated class, via p(y|x). In\\nthe next section we will introduce the sigmoid andsoftmax tools for classiﬁ-\\ncation.\\n3. An objective function for learning, usually involving minimizing error on\\ntraining examples. We will introduce the cross-entropy loss function .\\n4. An algorithm for optimizing the objective function. We introduce the stochas-\\ntic gradient descent algorithm.\\nLogistic regression has two phases:\\ntraining: We train the system (speciﬁcally the weights wandb) using stochastic\\ngradient descent and the cross-entropy loss.\\ntest: Given a test example xwe compute p(y|x)and return the higher probability\\nlabel y=1 ory=0.\\n5.1 The sigmoid function\\nThe goal of binary logistic regression is to train a classiﬁer that can make a binary\\ndecision about the class of a new input observation. Here we introduce the sigmoid\\nclassiﬁer that will help us make this decision.\\nConsider a single input observation x, which we will represent by a vector of fea-\\ntures[x1,x2,...,xn](we’ll show sample features in the next subsection). The classiﬁer\\noutput ycan be 1 (meaning the observation is a member of the class) or 0 (the ob-\\nservation is not a member of the class). We want to know the probability P(y=1|x)\\nthat this observation is a member of the class. So perhaps the decision is “positive', metadata={'source': '/content/5.pdf', 'page': 1}),\n",
              " Document(page_content='5.1 • T HE SIGMOID FUNCTION 3\\nsentiment” versus “negative sentiment”, the features represent counts of words in a\\ndocument, P(y=1|x)is the probability that the document has positive sentiment,\\nandP(y=0|x)is the probability that the document has negative sentiment.\\nLogistic regression solves this task by learning, from a training set, a vector of\\nweights and a bias term . Each weight wiis a real number, and is associated with one\\nof the input features xi. The weight wirepresents how important that input feature\\nis to the classiﬁcation decision, and can be positive (providing evidence that the in-\\nstance being classiﬁed belongs in the positive class) or negative (providing evidence\\nthat the instance being classiﬁed belongs in the negative class). Thus we might\\nexpect in a sentiment task the word awesome to have a high positive weight, and\\nabysmal to have a very negative weight. The bias term , also called the intercept , is bias term\\nintercept another real number that’s added to the weighted inputs.\\nTo make a decision on a test instance—after we’ve learned the weights in training—\\nthe classiﬁer ﬁrst multiplies each xiby its weight wi, sums up the weighted features,\\nand adds the bias term b. The resulting single number zexpresses the weighted sum\\nof the evidence for the class.\\nz=(n∑\\ni=1wixi)\\n+b (5.2)\\nIn the rest of the book we’ll represent such sums using the dot product notation dot product\\nfrom linear algebra. The dot product of two vectors aandb, written as a·b, is the\\nsum of the products of the corresponding elements of each vector. (Notice that we\\nrepresent vectors using the boldface notation b). Thus the following is an equivalent\\nformation to Eq. 5.2:\\nz=w·x+b (5.3)\\nBut note that nothing in Eq. 5.3 forces zto be a legal probability, that is, to lie\\nbetween 0 and 1. In fact, since weights are real-valued, the output might even be\\nnegative; zranges from−∞to∞.\\nFigure 5.1 The sigmoid function σ(z) =1\\n1+e−ztakes a real value and maps it to the range\\n(0,1). It is nearly linear around 0 but outlier values get squashed toward 0 or 1.\\nTo create a probability, we’ll pass zthrough the sigmoid function, σ(z). The sigmoid\\nsigmoid function (named because it looks like an s) is also called the logistic func-\\ntion, and gives logistic regression its name. The sigmoid has the following equation,logistic\\nfunction\\nshown graphically in Fig. 5.1:\\nσ(z) =1\\n1+e−z=1\\n1+exp(−z)(5.4)\\n(For the rest of the book, we’ll use the notation exp (x)to mean ex.) The sigmoid\\nhas a number of advantages; it takes a real-valued number and maps it into the range', metadata={'source': '/content/5.pdf', 'page': 2}),\n",
              " Document(page_content='4CHAPTER 5 • L OGISTIC REGRESSION\\n(0,1), which is just what we want for a probability. Because it is nearly linear around\\n0 but ﬂattens toward the ends, it tends to squash outlier values toward 0 or 1. And\\nit’s differentiable, which as we’ll see in Section 5.10 will be handy for learning.\\nWe’re almost there. If we apply the sigmoid to the sum of the weighted features,\\nwe get a number between 0 and 1. To make it a probability, we just need to make\\nsure that the two cases, p(y=1)andp(y=0), sum to 1. We can do this as follows:\\nP(y=1) = σ(w·x+b)\\n=1\\n1+exp(−(w·x+b))\\nP(y=0) = 1−σ(w·x+b)\\n=1−1\\n1+exp(−(w·x+b))\\n=exp(−(w·x+b))\\n1+exp(−(w·x+b))(5.5)\\nThe sigmoid function has the property\\n1−σ(x) =σ(−x) (5.6)\\nso we could also have expressed P(y=0)asσ(−(w·x+b)).\\nFinally, one terminological point. The input to the sigmoid function, the score\\nz=w·x+bfrom (5.3), is often called the logit . This is because the logit function logit\\nis the inverse of the sigmoid. The logit function is the log of the odds ratiop\\n1−p:\\nlogit(p) =σ−1(p) =lnp\\n1−p(5.7)\\nUsing the term logit forzis a way of reminding us that by using the sigmoid to turn\\nz(which ranges from −∞to∞) into a probability, we are implicitly interpreting zas\\nnot just any real-valued number, but as speciﬁcally a log odds.\\n5.2 Classiﬁcation with Logistic Regression\\nThe sigmoid function from the prior section thus gives us a way to take an instance\\nxand compute the probability P(y=1|x).\\nHow do we make a decision about which class to apply to a test instance x? For\\na given x, we say yes if the probability P(y=1|x)is more than .5, and no otherwise.\\nWe call .5 the decision boundary :decision\\nboundary\\ndecision (x) ={1 if P(y=1|x)>0.5\\n0 otherwise\\nLet’s have some examples of applying logistic regression as a classiﬁer for language\\ntasks.\\n5.2.1 Sentiment Classiﬁcation\\nSuppose we are doing binary sentiment classiﬁcation on movie review text, and\\nwe would like to know whether to assign the sentiment class +or−to a review', metadata={'source': '/content/5.pdf', 'page': 3}),\n",
              " Document(page_content=\"5.2 • C LASSIFICATION WITH LOGISTIC REGRESSION 5\\ndocument doc. We’ll represent each input observation by the 6 features x1...x6of\\nthe input shown in the following table; Fig. 5.2 shows the features in a sample mini\\ntest document.\\nVar Deﬁnition Value in Fig. 5.2\\nx1 count(positive lexicon words ∈doc) 3\\nx2 count(negative lexicon words ∈doc) 2\\nx3{1 if “no”∈doc\\n0 otherwise1\\nx4 count (1st and 2nd pronouns ∈doc) 3\\nx5{1 if “!”∈doc\\n0 otherwise0\\nx6 ln(word count of doc ) ln(66) =4.19\\nLet’s assume for the moment that we’ve already learned a real-valued weight for\\n It's hokey . There are virtually no surprises , and the writing is second-rate . So why was it so enjoyable  ? For one thing , the cast is great . Another nice touch is the music . I was overcome with the urge to get off the couch and start dancing .  It sucked me in , and it'll do the same to you  .x1=3x6=4.19x3=1x4=3x5=0x2=2\\nFigure 5.2 A sample mini test document showing the extracted features in the vector x.\\neach of these features, and that the 6 weights corresponding to the 6 features are\\n[2.5,−5.0,−1.2,0.5,2.0,0.7], while b= 0.1. (We’ll discuss in the next section how\\nthe weights are learned.) The weight w1, for example indicates how important a\\nfeature the number of positive lexicon words ( great ,nice,enjoyable , etc.) is to\\na positive sentiment decision, while w2tells us the importance of negative lexicon\\nwords. Note that w1=2.5 is positive, while w2=−5.0, meaning that negative words\\nare negatively associated with a positive sentiment decision, and are about twice as\\nimportant as positive words.\\nGiven these 6 features and the input review x,P(+|x)andP(−|x)can be com-\\nputed using Eq. 5.5:\\np(+|x) =P(y=1|x) = σ(w·x+b)\\n=σ([2.5,−5.0,−1.2,0.5,2.0,0.7]·[3,2,1,3,0,4.19]+0.1)\\n=σ(.833)\\n=0.70 (5.8)\\np(−|x) =P(y=0|x) = 1−σ(w·x+b)\\n=0.30\\n5.2.2 Other classiﬁcation tasks and features\\nLogistic regression is commonly applied to all sorts of NLP tasks, and any property\\nof the input can be a feature. Consider the task of period disambiguation : decidingperiod\\ndisambiguation\", metadata={'source': '/content/5.pdf', 'page': 4}),\n",
              " Document(page_content='6CHAPTER 5 • L OGISTIC REGRESSION\\nif a period is the end of a sentence or part of a word, by classifying each period\\ninto one of two classes EOS (end-of-sentence) and not-EOS. We might use features\\nlikex1below expressing that the current word is lower case (perhaps with a positive\\nweight), or that the current word is in our abbreviations dictionary (“Prof.”) (perhaps\\nwith a negative weight). A feature can also express a quite complex combination of\\nproperties. For example a period following an upper case word is likely to be an\\nEOS, but if the word itself is St.and the previous word is capitalized, then the\\nperiod is likely part of a shortening of the word street .\\nx1={1 if “ Case(wi) =Lower”\\n0 otherwise\\nx2={1 if “ wi∈AcronymDict”\\n0 otherwise\\nx3={\\n1 if “ wi=St. & Case(wi−1) =Cap”\\n0 otherwise\\nDesigning features: Features are generally designed by examining the training\\nset with an eye to linguistic intuitions and the linguistic literature on the domain. A\\ncareful error analysis on the training set or devset of an early version of a system\\noften provides insights into features.\\nFor some tasks it is especially helpful to build complex features that are combi-\\nnations of more primitive features. We saw such a feature for period disambiguation\\nabove, where a period on the word St.was less likely to be the end of the sentence\\nif the previous word was capitalized. For logistic regression and naive Bayes these\\ncombination features or feature interactions have to be designed by hand.feature\\ninteractions\\nFor many tasks (especially when feature values can reference speciﬁc words)\\nwe’ll need large numbers of features. Often these are created automatically via fea-\\nture templates , abstract speciﬁcations of features. For example a bigram templatefeature\\ntemplates\\nfor period disambiguation might create a feature for every pair of words that occurs\\nbefore a period in the training set. Thus the feature space is sparse, since we only\\nhave to create a feature if that n-gram exists in that position in the training set. The\\nfeature is generally created as a hash from the string descriptions. A user description\\nof a feature as, “bigram(American breakfast)” is hashed into a unique integer ithat\\nbecomes the feature number fi.\\nIn order to avoid the extensive human effort of feature design, recent research in\\nNLP has focused on representation learning : ways to learn features automatically\\nin an unsupervised way from the input. We’ll introduce methods for representation\\nlearning in Chapter 6 and Chapter 7.\\nScaling input features: When different input features have extremely different\\nranges of values, it’s common to rescale them so they have comparable ranges. We\\nstandardize input values by centering them to result in a zero mean and a standard standardize\\ndeviation of one (this transformation is sometimes called the z-score ). That is, if µiz-score\\nis the mean of the values of feature xiacross the mobservations in the input dataset,\\nandσiis the standard deviation of the values of features xiacross the input dataset,\\nwe can replace each feature xiby a new feature x′\\nicomputed as follows:\\nµi=1\\nmm∑\\nj=1x(j)\\ni σi=\\ued6a\\ued6b\\ued6b√1\\nmm∑\\nj=1(\\nx(j)\\ni−µi)2\\nx′\\ni=xi−µi\\nσi(5.9)', metadata={'source': '/content/5.pdf', 'page': 5}),\n",
              " Document(page_content='5.2 • C LASSIFICATION WITH LOGISTIC REGRESSION 7\\nAlternatively, we can normalize the input features values to lie between 0 and 1: normalize\\nx′\\ni=xi−min(xi)\\nmax(xi)−min(xi)(5.10)\\nHaving input data with comparable range is useful when comparing values across\\nfeatures. Data scaling is especially important in large neural networks, since it helps\\nspeed up gradient descent.\\n5.2.3 Processing many examples at once\\nWe’ve shown the equations for logistic regression for a single example. But in prac-\\ntice we’ll of course want to process an entire test set with many examples. Let’s\\nsuppose we have a test set consisting of mtest examples each of which we’d like to\\nclassify. We’ll continue to use the notation from page 2, in which a superscript value\\nin parentheses refers to the example index in some set of data (either for training or\\nfor test). So in this case each test example x(i)has a feature vector x(i), 1≤i≤m.\\n(As usual, we’ll represent vectors and matrices in bold.)\\nOne way to compute each output value ˆ y(i)is just to have a for-loop, and compute\\neach test example one at a time:\\nforeach x(i)in input [x(1),x(2),...,x(m)]\\ny(i)=σ(w·x(i)+b) (5.11)\\nFor the ﬁrst 3 test examples, then, we would be separately computing the pre-\\ndicted ˆ y(i)as follows:\\nP(y(1)=1|x(1)) = σ(w·x(1)+b)\\nP(y(2)=1|x(2)) = σ(w·x(2)+b)\\nP(y(3)=1|x(3)) = σ(w·x(3)+b)\\nBut it turns out that we can slightly modify our original equation Eq. 5.5 to do\\nthis much more efﬁciently. We’ll use matrix arithmetic to assign a class to all the\\nexamples with one matrix operation!\\nFirst, we’ll pack all the input feature vectors for each input xinto a single input\\nmatrix X, where each row iis a row vector consisting of the feature vector for in-\\nput example x(i)(i.e., the vector x(i)). Assuming each example has ffeatures and\\nweights, Xwill therefore be a matrix of shape [m×f], as follows:\\nX=\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0x(1)\\n1x(1)\\n2...x(1)\\nf\\nx(2)\\n1x(2)\\n2...x(2)\\nf\\nx(3)\\n1x(3)\\n2...x(3)\\nf\\n...\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb(5.12)\\nNow if we introduce bas a vector of length mwhich consists of the scalar bias\\nterm brepeated mtimes, b= [b,b,...,b], and ˆ y= [ˆy(1),ˆy(2)...,ˆy(m)]as the vector of\\noutputs (one scalar ˆ y(i)for each input x(i)and its feature vector x(i)), and represent\\nthe weight vector was a column vector, we can compute all the outputs with a single\\nmatrix multiplication and one addition:\\ny=Xw+b (5.13)', metadata={'source': '/content/5.pdf', 'page': 6}),\n",
              " Document(page_content='8CHAPTER 5 • L OGISTIC REGRESSION\\nYou should convince yourself that Eq. 5.13 computes the same thing as our for-loop\\nin Eq. 5.11. For example ˆ y(1), the ﬁrst entry of the output vector y, will correctly be:\\nˆy(1)= [x(1)\\n1,x(1)\\n2,...,x(1)\\nf]·[w1,w2,...,wf]+b (5.14)\\nNote that we had to reorder Xandwfrom the order they appeared in in Eq. 5.5 to\\nmake the multiplications come out properly. Here is Eq. 5.13 again with the shapes\\nshown:\\ny=X w +b\\n(m×1) ( m×f)(f×1) (m×1) (5.15)\\nModern compilers and compute hardware can compute this matrix operation\\nvery efﬁciently, making the computation much faster, which becomes important\\nwhen training or testing on very large datasets.\\n5.2.4 Choosing a classiﬁer\\nLogistic regression has a number of advantages over naive Bayes. Naive Bayes has\\noverly strong conditional independence assumptions. Consider two features which\\nare strongly correlated; in fact, imagine that we just add the same feature f1twice.\\nNaive Bayes will treat both copies of f1as if they were separate, multiplying them\\nboth in, overestimating the evidence. By contrast, logistic regression is much more\\nrobust to correlated features; if two features f1and f2are perfectly correlated, re-\\ngression will simply assign part of the weight to w1and part to w2. Thus when\\nthere are many correlated features, logistic regression will assign a more accurate\\nprobability than naive Bayes. So logistic regression generally works better on larger\\ndocuments or datasets and is a common default.\\nDespite the less accurate probabilities, naive Bayes still often makes the correct\\nclassiﬁcation decision. Furthermore, naive Bayes can work extremely well (some-\\ntimes even better than logistic regression) on very small datasets (Ng and Jordan,\\n2002) or short documents (Wang and Manning, 2012). Furthermore, naive Bayes is\\neasy to implement and very fast to train (there’s no optimization step). So it’s still a\\nreasonable approach to use in some situations.\\n5.3 Multinomial logistic regression\\nSometimes we need more than two classes. Perhaps we might want to do 3-way\\nsentiment classiﬁcation (positive, negative, or neutral). Or we could be assigning\\nsome of the labels we will introduce in Chapter 8, like the part of speech of a word\\n(choosing from 10, 30, or even 50 different parts of speech), or the named entity\\ntype of a phrase (choosing from tags like person, location, organization).\\nIn such cases we use multinomial logistic regression , also called softmax re-multinomial\\nlogistic\\nregressiongression (in older NLP literature you will sometimes see the name maxent classi-\\nﬁer). In multinomial logistic regression we want to label each observation with a\\nclass kfrom a set of Kclasses, under the stipulation that only one of these classes is\\nthe correct one (sometimes called hard classiﬁcation ; an observation can not be in\\nmultiple classes). Let’s use the following representation: the output yfor each input\\nxwill be a vector of length K. If class cis the correct class, we’ll set yc=1, and\\nset all the other elements of yto be 0, i.e., yc=1 and yj=0∀j̸=c. A vector like', metadata={'source': '/content/5.pdf', 'page': 7}),\n",
              " Document(page_content='5.3 • M ULTINOMIAL LOGISTIC REGRESSION 9\\nthisy, with one value=1 and the rest 0, is called a one-hot vector . The job of the\\nclassiﬁer is to produce an estimate vector ˆ y. For each class k, the value ˆ ykwill be\\nthe classiﬁer’s estimate of the probability p(yk=1|x).\\n5.3.1 Softmax\\nThe multinomial logistic classiﬁer uses a generalization of the sigmoid, called the\\nsoftmax function, to compute p(yk=1|x). The softmax function takes a vector softmax\\nz= [z1,z2,...,zK]ofKarbitrary values and maps them to a probability distribution,\\nwith each value in the range [0,1], and all the values summing to 1. Like the sigmoid,\\nit is an exponential function.\\nFor a vector zof dimensionality K, the softmax is deﬁned as:\\nsoftmax (zi) =exp(zi)∑K\\nj=1exp(zj)1≤i≤K (5.16)\\nThe softmax of an input vector z= [z1,z2,...,zK]is thus a vector itself:\\nsoftmax (z) =[\\nexp(z1)∑K\\ni=1exp(zi),exp(z2)∑K\\ni=1exp(zi),...,exp(zK)∑K\\ni=1exp(zi)]\\n(5.17)\\nThe denominator∑K\\ni=1exp(zi)is used to normalize all the values into probabilities.\\nThus for example given a vector:\\nz= [0.6,1.1,−1.5,1.2,3.2,−1.1]\\nthe resulting (rounded) softmax( z) is\\n[0.055,0.090,0.006,0.099,0.74,0.010]\\nLike the sigmoid, the softmax has the property of squashing values toward 0 or 1.\\nThus if one of the inputs is larger than the others, it will tend to push its probability\\ntoward 1, and suppress the probabilities of the smaller inputs.\\nFinally, note that, just as for the sigmoid, we refer to z, the vector of scores that\\nis the input to the softmax, as logits (see (5.7).\\n5.3.2 Applying softmax in logistic regression\\nWhen we apply softmax for logistic regression, the input will (just as for the sig-\\nmoid) be the dot product between a weight vector wand an input vector x(plus a\\nbias). But now we’ll need separate weight vectors wkand bias bkfor each of the K\\nclasses. The probability of each of our output classes ˆ ykcan thus be computed as:\\np(yk=1|x) =exp(wk·x+bk)\\nK∑\\nj=1exp(wj·x+bj)(5.18)\\nThe form of Eq. 5.18 makes it seem that we would compute each output sep-\\narately. Instead, it’s more common to set up the equation for more efﬁcient com-\\nputation by modern vector processing hardware. We’ll do this by representing the\\nset of Kweight vectors as a weight matrix Wand a bias vector b. Each row kof', metadata={'source': '/content/5.pdf', 'page': 8}),\n",
              " Document(page_content='10 CHAPTER 5 • L OGISTIC REGRESSION\\nWcorresponds to the vector of weights wk.Wthus has shape [K×f], for Kthe\\nnumber of output classes and fthe number of input features. The bias vector bhas\\none value for each of the Koutput classes. If we represent the weights in this way,\\nwe can compute ˆy, the vector of output probabilities for each of the Kclasses, by a\\nsingle elegant equation:\\nˆy=softmax (Wx+b) (5.19)\\nIf you work out the matrix arithmetic, you can see that the estimated score of\\nthe ﬁrst output class ˆ y1(before we take the softmax) will correctly turn out to be\\nw1·x+b1.\\nFig. 5.3 shows an intuition of the role of the weight vector versus weight matrix\\nin the computation of the output class probabilities for binary versus multinomial\\nlogistic regression.\\nBinary Logistic Regression\\nw[f ⨉1]Outputsigmoid[1⨉f]Input wordsp(+) = 1- p(-)…y^xyInput featurevector [scalar]positive lexiconwords = 1count of “no” = 0wordcount=3x1x2x3xfdessert   was    greatWeight vector\\nMultinomial Logistic Regression\\nW[f⨉1]Outputsoftmax[K⨉f]Input wordsp(+)…y1^y2^y3^xyInput featurevector [K⨉1]positive lexiconwords = 1count of “no” = 0wordcount=3x1x2x3xfdessert   was    greatp(-)p(neut)Weight matrixThese f red weightsare a row of W correspondingto weight vector w3,(= weights for class 3)\\nFigure 5.3 Binary versus multinomial logistic regression. Binary logistic regression uses a\\nsingle weight vector w, and has a scalar output ˆ y. In multinomial logistic regression we have\\nKseparate weight vectors corresponding to the Kclasses, all packed into a single weight\\nmatrix W, and a vector output ˆy.', metadata={'source': '/content/5.pdf', 'page': 9}),\n",
              " Document(page_content='5.4 • L EARNING IN LOGISTIC REGRESSION 11\\n5.3.3 Features in Multinomial Logistic Regression\\nFeatures in multinomial logistic regression act like features in binary logistic regres-\\nsion, with the difference mentioned above that we’ll need separate weight vectors\\nand biases for each of the Kclasses. Recall our binary exclamation point feature x5\\nfrom page 5:\\nx5={1 if “!”∈doc\\n0 otherwise\\nIn binary classiﬁcation a positive weight w5on a feature inﬂuences the classiﬁer\\ntoward y=1 (positive sentiment) and a negative weight inﬂuences it toward y=0\\n(negative sentiment) with the absolute value indicating how important the feature\\nis. For multinomial logistic regression, by contrast, with separate weights for each\\nclass, a feature can be evidence for or against each individual class.\\nIn 3-way multiclass sentiment classiﬁcation, for example, we must assign each\\ndocument one of the 3 classes +,−, or 0 (neutral). Now a feature related to excla-\\nmation marks might have a negative weight for 0 documents, and a positive weight\\nfor+or−documents:\\nFeature Deﬁnition w5,+w5,−w5,0\\nf5(x){1 if “!”∈doc\\n0 otherwise3.5 3 .1−5.3\\nBecause these feature weights are dependent both on the input text and the output\\nclass, we sometimes make this dependence explicit and represent the features them-\\nselves as f(x,y): a function of both the input and the class. Using such a notation\\nf5(x)above could be represented as three features f5(x,+),f5(x,−), and f5(x,0),\\neach of which has a single weight. We’ll use this kind of notation in our description\\nof the CRF in Chapter 8.\\n5.4 Learning in Logistic Regression\\nHow are the parameters of the model, the weights wand bias b, learned? Logistic\\nregression is an instance of supervised classiﬁcation in which we know the correct\\nlabel y(either 0 or 1) for each observation x. What the system produces via Eq. 5.5\\nis ˆy, the system’s estimate of the true y. We want to learn parameters (meaning w\\nandb) that make ˆ yfor each training observation as close as possible to the true y.\\nThis requires two components that we foreshadowed in the introduction to the\\nchapter. The ﬁrst is a metric for how close the current label ( ˆ y) is to the true gold\\nlabel y. Rather than measure similarity, we usually talk about the opposite of this:\\nthedistance between the system output and the gold output, and we call this distance\\nthelossfunction or the cost function . In the next section we’ll introduce the loss loss\\nfunction that is commonly used for logistic regression and also for neural networks,\\nthecross-entropy loss .\\nThe second thing we need is an optimization algorithm for iteratively updating\\nthe weights so as to minimize this loss function. The standard algorithm for this is\\ngradient descent ; we’ll introduce the stochastic gradient descent algorithm in the\\nfollowing section.', metadata={'source': '/content/5.pdf', 'page': 10}),\n",
              " Document(page_content='12 CHAPTER 5 • L OGISTIC REGRESSION\\nWe’ll describe these algorithms for the simpler case of binary logistic regres-\\nsion in the next two sections, and then turn to multinomial logistic regression in\\nSection 5.8.\\n5.5 The cross-entropy loss function\\nWe need a loss function that expresses, for an observation x, how close the classiﬁer\\noutput ( ˆ y=σ(w·x+b)) is to the correct output ( y, which is 0 or 1). We’ll call this:\\nL(ˆy,y) = How much ˆ ydiffers from the true y (5.20)\\nWe do this via a loss function that prefers the correct class labels of the train-\\ning examples to be more likely . This is called conditional maximum likelihood\\nestimation : we choose the parameters w,bthatmaximize the log probability of\\nthe true ylabels in the training data given the observations x. The resulting loss\\nfunction is the negative log likelihood loss , generally called the cross-entropy loss .cross-entropy\\nloss\\nLet’s derive this loss function, applied to a single observation x. We’d like to\\nlearn weights that maximize the probability of the correct label p(y|x). Since there\\nare only two discrete outcomes (1 or 0), this is a Bernoulli distribution, and we can\\nexpress the probability p(y|x)that our classiﬁer produces for one observation as the\\nfollowing (keeping in mind that if y=1, Eq. 5.21 simpliﬁes to ˆ y; ify=0, Eq. 5.21\\nsimpliﬁes to 1−ˆy):\\np(y|x) = ˆyy(1−ˆy)1−y(5.21)\\nNow we take the log of both sides. This will turn out to be handy mathematically,\\nand doesn’t hurt us; whatever values maximize a probability will also maximize the\\nlog of the probability:\\nlogp(y|x) = log[\\nˆyy(1−ˆy)1−y]\\n=ylog ˆy+(1−y)log(1−ˆy) (5.22)\\nEq. 5.22 describes a log likelihood that should be maximized. In order to turn this\\ninto a loss function (something that we need to minimize), we’ll just ﬂip the sign on\\nEq. 5.22. The result is the cross-entropy loss LCE:\\nLCE(ˆy,y) =−logp(y|x) =−[ylog ˆy+(1−y)log(1−ˆy)] (5.23)\\nFinally, we can plug in the deﬁnition of ˆ y=σ(w·x+b):\\nLCE(ˆy,y) =−[ylogσ(w·x+b)+(1−y)log(1−σ(w·x+b))] (5.24)\\nLet’s see if this loss function does the right thing for our example from Fig. 5.2. We\\nwant the loss to be smaller if the model’s estimate is close to correct, and bigger if\\nthe model is confused. So ﬁrst let’s suppose the correct gold label for the sentiment\\nexample in Fig. 5.2 is positive, i.e., y=1. In this case our model is doing well, since\\nfrom Eq. 5.8 it indeed gave the example a higher probability of being positive (.70)\\nthan negative (.30). If we plug σ(w·x+b) =.70 and y=1 into Eq. 5.24, the right\\nside of the equation drops out, leading to the following loss (we’ll use log to mean', metadata={'source': '/content/5.pdf', 'page': 11}),\n",
              " Document(page_content='5.6 • G RADIENT DESCENT 13\\nnatural log when the base is not speciﬁed):\\nLCE(ˆy,y) =−[ylogσ(w·x+b)+(1−y)log(1−σ(w·x+b))]\\n=−[logσ(w·x+b)]\\n=−log(.70)\\n= .36\\nBy contrast, let’s pretend instead that the example in Fig. 5.2 was actually negative,\\ni.e., y=0 (perhaps the reviewer went on to say “But bottom line, the movie is\\nterrible! I beg you not to see it!”). In this case our model is confused and we’d want\\nthe loss to be higher. Now if we plug y=0 and 1−σ(w·x+b) =.31 from Eq. 5.8\\ninto Eq. 5.24, the left side of the equation drops out:\\nLCE(ˆy,y) =−[ylogσ(w·x+b)+(1−y)log(1−σ(w·x+b))]\\n= −[log(1−σ(w·x+b))]\\n= −log(.30)\\n= 1.2\\nSure enough, the loss for the ﬁrst classiﬁer (.36) is less than the loss for the second\\nclassiﬁer (1.2).\\nWhy does minimizing this negative log probability do what we want? A perfect\\nclassiﬁer would assign probability 1 to the correct outcome ( y=1 or y=0) and\\nprobability 0 to the incorrect outcome. That means if yequals 1, the higher ˆ yis (the\\ncloser it is to 1), the better the classiﬁer; the lower ˆ yis (the closer it is to 0), the\\nworse the classiﬁer. If yequals 0, instead, the higher 1 −ˆyis (closer to 1), the better\\nthe classiﬁer. The negative log of ˆ y(if the true yequals 1) or 1−ˆy(if the true y\\nequals 0) is a convenient loss metric since it goes from 0 (negative log of 1, no loss)\\nto inﬁnity (negative log of 0, inﬁnite loss). This loss function also ensures that as\\nthe probability of the correct answer is maximized, the probability of the incorrect\\nanswer is minimized; since the two sum to one, any increase in the probability of the\\ncorrect answer is coming at the expense of the incorrect answer. It’s called the cross-\\nentropy loss, because Eq. 5.22 is also the formula for the cross-entropy between the\\ntrue probability distribution yand our estimated distribution ˆ y.\\nNow we know what we want to minimize; in the next section, we’ll see how to\\nﬁnd the minimum.\\n5.6 Gradient Descent\\nOur goal with gradient descent is to ﬁnd the optimal weights: minimize the loss\\nfunction we’ve deﬁned for the model. In Eq. 5.25 below, we’ll explicitly represent\\nthe fact that the loss function Lis parameterized by the weights, which we’ll refer\\nto in machine learning in general as θ(in the case of logistic regression θ=w,b).\\nSo the goal is to ﬁnd the set of weights which minimizes the loss function, averaged\\nover all examples:\\nˆθ=argmin\\nθ1\\nmm∑\\ni=1LCE(f(x(i);θ),y(i)) (5.25)\\nHow shall we ﬁnd the minimum of this (or any) loss function? Gradient descent is a\\nmethod that ﬁnds a minimum of a function by ﬁguring out in which direction (in the', metadata={'source': '/content/5.pdf', 'page': 12}),\n",
              " Document(page_content='14 CHAPTER 5 • L OGISTIC REGRESSION\\nspace of the parameters θ) the function’s slope is rising the most steeply, and moving\\nin the opposite direction. The intuition is that if you are hiking in a canyon and trying\\nto descend most quickly down to the river at the bottom, you might look around\\nyourself 360 degrees, ﬁnd the direction where the ground is sloping the steepest,\\nand walk downhill in that direction.\\nFor logistic regression, this loss function is conveniently convex . A convex func- convex\\ntion has at most one minimum; there are no local minima to get stuck in, so gradient\\ndescent starting from any point is guaranteed to ﬁnd the minimum. (By contrast,\\nthe loss for multi-layer neural networks is non-convex, and gradient descent may\\nget stuck in local minima for neural network training and never ﬁnd the global opti-\\nmum.)\\nAlthough the algorithm (and the concept of gradient) are designed for direction\\nvectors , let’s ﬁrst consider a visualization of the case where the parameter of our\\nsystem is just a single scalar w, shown in Fig. 5.4.\\nGiven a random initialization of wat some value w1, and assuming the loss\\nfunction Lhappened to have the shape in Fig. 5.4, we need the algorithm to tell us\\nwhether at the next iteration we should move left (making w2smaller than w1) or\\nright (making w2bigger than w1) to reach the minimum.\\nwLoss\\n0w1wminslope of loss at w1 is negative(goal)one stepof gradientdescent\\nFigure 5.4 The ﬁrst step in iteratively ﬁnding the minimum of this loss function, by moving\\nwin the reverse direction from the slope of the function. Since the slope is negative, we need\\nto move win a positive direction, to the right. Here superscripts are used for learning steps,\\nsow1means the initial value of w(which is 0), w2the value at the second step, and so on.\\nThe gradient descent algorithm answers this question by ﬁnding the gradient gradient\\nof the loss function at the current point and moving in the opposite direction. The\\ngradient of a function of many variables is a vector pointing in the direction of the\\ngreatest increase in a function. The gradient is a multi-variable generalization of the\\nslope, so for a function of one variable like the one in Fig. 5.4, we can informally\\nthink of the gradient as the slope. The dotted line in Fig. 5.4 shows the slope of this\\nhypothetical loss function at point w=w1. You can see that the slope of this dotted\\nline is negative. Thus to ﬁnd the minimum, gradient descent tells us to go in the\\nopposite direction: moving win a positive direction.\\nThe magnitude of the amount to move in gradient descent is the value of the\\nsloped\\ndwL(f(x;w),y)weighted by a learning rate η. A higher (faster) learning learning rate\\nrate means that we should move wmore on each step. The change we make in our\\nparameter is the learning rate times the gradient (or the slope, in our single-variable', metadata={'source': '/content/5.pdf', 'page': 13}),\n",
              " Document(page_content='5.6 • G RADIENT DESCENT 15\\nexample):\\nwt+1=wt−ηd\\ndwL(f(x;w),y) (5.26)\\nNow let’s extend the intuition from a function of one scalar variable wto many\\nvariables, because we don’t just want to move left or right, we want to know where\\nin the N-dimensional space (of the Nparameters that make up θ) we should move.\\nThe gradient is just such a vector; it expresses the directional components of the\\nsharpest slope along each of those Ndimensions. If we’re just imagining two weight\\ndimensions (say for one weight wand one bias b), the gradient might be a vector with\\ntwo orthogonal components, each of which tells us how much the ground slopes in\\nthewdimension and in the bdimension. Fig. 5.5 shows a visualization of the value\\nof a 2-dimensional gradient vector taken at the red point.\\nIn an actual logistic regression, the parameter vector wis much longer than 1 or\\n2, since the input feature vector xcan be quite long, and we need a weight wifor\\neach xi. For each dimension/variable wiinw(plus the bias b), the gradient will have\\na component that tells us the slope with respect to that variable. In each dimension\\nwi, we express the slope as a partial derivative∂\\n∂wiof the loss function. Essentially\\nwe’re asking: “How much would a small change in that variable wiinﬂuence the\\ntotal loss function L?”\\nFormally, then, the gradient of a multi-variable function fis a vector in which\\neach component expresses the partial derivative of fwith respect to one of the vari-\\nables. We’ll use the inverted Greek delta symbol ∇to refer to the gradient, and\\nrepresent ˆ yasf(x;θ)to make the dependence on θmore obvious:\\n∇L(f(x;θ),y) =\\uf8ee\\n\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0∂\\n∂w1L(f(x;θ),y)\\n∂\\n∂w2L(f(x;θ),y)\\n...\\n∂\\n∂wnL(f(x;θ),y)\\n∂\\n∂bL(f(x;θ),y)\\uf8f9\\n\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb(5.27)\\nThe ﬁnal equation for updating θbased on the gradient is thus\\nθt+1=θt−η∇L(f(x;θ),y) (5.28)\\nCost(w,b)\\nwb\\nFigure 5.5 Visualization of the gradient vector at the red point in two dimensions wand\\nb, showing a red arrow in the x-y plane pointing in the direction we will go to look for the\\nminimum: the opposite direction of the gradient (recall that the gradient points in the direction\\nof increase not decrease).', metadata={'source': '/content/5.pdf', 'page': 14}),\n",
              " Document(page_content='16 CHAPTER 5 • L OGISTIC REGRESSION\\n5.6.1 The Gradient for Logistic Regression\\nIn order to update θ, we need a deﬁnition for the gradient ∇L(f(x;θ),y). Recall that\\nfor logistic regression, the cross-entropy loss function is:\\nLCE(ˆy,y) =−[ylogσ(w·x+b)+(1−y)log(1−σ(w·x+b))] (5.29)\\nIt turns out that the derivative of this function for one observation vector xis Eq. 5.30\\n(the interested reader can see Section 5.10 for the derivation of this equation):\\n∂LCE(ˆy,y)\\n∂wj= [σ(w·x+b)−y]xj\\n= ( ˆy−y)xj (5.30)\\nYou’ll also sometimes see this equation in the equivalent form:\\n∂LCE(ˆy,y)\\n∂wj=−(y−ˆy)xj (5.31)\\nNote in these equations that the gradient with respect to a single weight wjrep-\\nresents a very intuitive value: the difference between the true yand our estimated\\nˆy=σ(w·x+b)for that observation, multiplied by the corresponding input value\\nxj.\\n5.6.2 The Stochastic Gradient Descent Algorithm\\nStochastic gradient descent is an online algorithm that minimizes the loss function\\nby computing its gradient after each training example, and nudging θin the right\\ndirection (the opposite direction of the gradient). (An “online algorithm” is one that\\nprocesses its input example by example, rather than waiting until it sees the entire\\ninput.) Fig. 5.6 shows the algorithm.\\nThe learning rate ηis ahyperparameter that must be adjusted. If it’s too high, hyperparameter\\nthe learner will take steps that are too large, overshooting the minimum of the loss\\nfunction. If it’s too low, the learner will take steps that are too small, and take too\\nlong to get to the minimum. It is common to start with a higher learning rate and then\\nslowly decrease it, so that it is a function of the iteration kof training; the notation\\nηkcan be used to mean the value of the learning rate at iteration k.\\nWe’ll discuss hyperparameters in more detail in Chapter 7, but in short, they are\\na special kind of parameter for any machine learning model. Unlike regular param-\\neters of a model (weights like wandb), which are learned by the algorithm from\\nthe training set, hyperparameters are special parameters chosen by the algorithm\\ndesigner that affect how the algorithm works.\\n5.6.3 Working through an example\\nLet’s walk through a single step of the gradient descent algorithm. We’ll use a\\nsimpliﬁed version of the example in Fig. 5.2 as it sees a single observation x, whose\\ncorrect value is y=1 (this is a positive review), and with a feature vector x= [x1,x2]\\nconsisting of these two features:\\nx1=3 (count of positive lexicon words)\\nx2=2 (count of negative lexicon words)', metadata={'source': '/content/5.pdf', 'page': 15}),\n",
              " Document(page_content='5.6 • G RADIENT DESCENT 17\\nfunction STOCHASTIC GRADIENT DESCENT (L(),f(),x,y)returns θ\\n# where: L is the loss function\\n# f is a function parameterized by θ\\n# x is the set of training inputs x(1),x(2),...,x(m)\\n# y is the set of training outputs (labels) y(1),y(2),...,y(m)\\nθ←0\\nrepeat til done # see caption\\nFor each training tuple (x(i),y(i))(in random order)\\n1. Optional (for reporting): # How are we doing on this tuple?\\nCompute ˆ y(i)=f(x(i);θ)# What is our estimated output ˆ y?\\nCompute the loss L(ˆy(i),y(i))# How far off is ˆ y(i)from the true output y(i)?\\n2.g←∇θL(f(x(i);θ),y(i)) # How should we move θto maximize loss?\\n3.θ←θ−ηg # Go the other way instead\\nreturn θ\\nFigure 5.6 The stochastic gradient descent algorithm. Step 1 (computing the loss) is used\\nmainly to report how well we are doing on the current tuple; we don’t need to compute the\\nloss in order to compute the gradient. The algorithm can terminate when it converges (or\\nwhen the gradient norm <ϵ), or when progress halts (for example when the loss starts going\\nup on a held-out set).\\nLet’s assume the initial weights and bias in θ0are all set to 0, and the initial learning\\nrateηis 0.1:\\nw1=w2=b=0\\nη=0.1\\nThe single update step requires that we compute the gradient, multiplied by the\\nlearning rate\\nθt+1=θt−η∇θL(f(x(i);θ),y(i))\\nIn our mini example there are three parameters, so the gradient vector has 3 dimen-\\nsions, for w1,w2, and b. We can compute the ﬁrst gradient as follows:\\n∇w,bL=\\uf8ee\\n\\uf8ef\\uf8f0∂LCE(ˆy,y)\\n∂w1∂LCE(ˆy,y)\\n∂w2∂LCE(ˆy,y)\\n∂b\\uf8f9\\n\\uf8fa\\uf8fb=\\uf8ee\\n\\uf8f0(σ(w·x+b)−y)x1\\n(σ(w·x+b)−y)x2\\nσ(w·x+b)−y\\uf8f9\\n\\uf8fb=\\uf8ee\\n\\uf8f0(σ(0)−1)x1\\n(σ(0)−1)x2\\nσ(0)−1\\uf8f9\\n\\uf8fb=\\uf8ee\\n\\uf8f0−0.5x1\\n−0.5x2\\n−0.5\\uf8f9\\n\\uf8fb=\\uf8ee\\n\\uf8f0−1.5\\n−1.0\\n−0.5\\uf8f9\\n\\uf8fb\\nNow that we have a gradient, we compute the new parameter vector θ1by moving\\nθ0in the opposite direction from the gradient:\\nθ1=\\uf8ee\\n\\uf8f0w1\\nw2\\nb\\uf8f9\\n\\uf8fb−η\\uf8ee\\n\\uf8f0−1.5\\n−1.0\\n−0.5\\uf8f9\\n\\uf8fb=\\uf8ee\\n\\uf8f0.15\\n.1\\n.05\\uf8f9\\n\\uf8fb\\nSo after one step of gradient descent, the weights have shifted to be: w1=.15,\\nw2=.1, and b=.05.\\nNote that this observation xhappened to be a positive example. We would expect\\nthat after seeing more negative examples with high counts of negative words, that\\nthe weight w2would shift to have a negative value.', metadata={'source': '/content/5.pdf', 'page': 16}),\n",
              " Document(page_content='18 CHAPTER 5 • L OGISTIC REGRESSION\\n5.6.4 Mini-batch training\\nStochastic gradient descent is called stochastic because it chooses a single random\\nexample at a time, moving the weights so as to improve performance on that single\\nexample. That can result in very choppy movements, so it’s common to compute the\\ngradient over batches of training instances rather than a single instance.\\nFor example in batch training we compute the gradient over the entire dataset. batch training\\nBy seeing so many examples, batch training offers a superb estimate of which di-\\nrection to move the weights, at the cost of spending a lot of time processing every\\nsingle example in the training set to compute this perfect direction.\\nA compromise is mini-batch training: we train on a group of mexamples (per- mini-batch\\nhaps 512, or 1024) that is less than the whole dataset. (If mis the size of the dataset,\\nthen we are doing batch gradient descent; if m=1, we are back to doing stochas-\\ntic gradient descent.) Mini-batch training also has the advantage of computational\\nefﬁciency. The mini-batches can easily be vectorized, choosing the size of the mini-\\nbatch based on the computational resources. This allows us to process all the exam-\\nples in one mini-batch in parallel and then accumulate the loss, something that’s not\\npossible with individual or batch training.\\nWe just need to deﬁne mini-batch versions of the cross-entropy loss function\\nwe deﬁned in Section 5.5 and the gradient in Section 5.6.1. Let’s extend the cross-\\nentropy loss for one example from Eq. 5.23 to mini-batches of size m. We’ll continue\\nto use the notation that x(i)andy(i)mean the ith training features and training label,\\nrespectively. We make the assumption that the training examples are independent:\\nlogp(training labels ) = logm∏\\ni=1p(y(i)|x(i))\\n=m∑\\ni=1logp(y(i)|x(i))\\n=−m∑\\ni=1LCE(ˆy(i),y(i)) (5.32)\\nNow the cost function for the mini-batch of mexamples is the average loss for each\\nexample:\\nCost(ˆy,y) =1\\nmm∑\\ni=1LCE(ˆy(i),y(i))\\n=−1\\nmm∑\\ni=1y(i)logσ(w·x(i)+b)+(1−y(i))log(\\n1−σ(w·x(i)+b))\\n(5.33)\\nThe mini-batch gradient is the average of the individual gradients from Eq. 5.30:\\n∂Cost(ˆy,y)\\n∂wj=1\\nmm∑\\ni=1[\\nσ(w·x(i)+b)−y(i)]\\nx(i)\\nj(5.34)\\nInstead of using the sum notation, we can more efﬁciently compute the gradient\\nin its matrix form, following the vectorization we saw on page 7, where we have a\\nmatrix Xof size [m×f]representing the minputs in the batch, and a vector yof size\\n[m×1]representing the correct outputs:', metadata={'source': '/content/5.pdf', 'page': 17}),\n",
              " Document(page_content='5.7 • R EGULARIZATION 19\\n∂Cost(ˆy,y)\\n∂w=1\\nm(ˆy−y)⊺X\\n=1\\nm(σ(Xw+b)−y)⊺X (5.35)\\n5.7 Regularization\\nNumquam ponenda est pluralitas sine necessitate\\n‘Plurality should never be proposed unless needed’\\nWilliam of Occam\\nThere is a problem with learning weights that make the model perfectly match the\\ntraining data. If a feature is perfectly predictive of the outcome because it happens\\nto only occur in one class, it will be assigned a very high weight. The weights for\\nfeatures will attempt to perfectly ﬁt details of the training set, in fact too perfectly,\\nmodeling noisy factors that just accidentally correlate with the class. This problem is\\ncalled overﬁtting . A good model should be able to generalize well from the training overﬁtting\\ngeneralize data to the unseen test set, but a model that overﬁts will have poor generalization.\\nTo avoid overﬁtting, a new regularization term R(θ)is added to the objective regularization\\nfunction in Eq. 5.25, resulting in the following objective for a batch of mexam-\\nples (slightly rewritten from Eq. 5.25 to be maximizing log probability rather than\\nminimizing loss, and removing the1\\nmterm which doesn’t affect the argmax):\\nˆθ=argmax\\nθm∑\\ni=1logP(y(i)|x(i))−αR(θ) (5.36)\\nThe new regularization term R(θ)is used to penalize large weights. Thus a setting\\nof the weights that matches the training data perfectly— but uses many weights with\\nhigh values to do so—will be penalized more than a setting that matches the data a\\nlittle less well, but does so using smaller weights. There are two common ways to\\ncompute this regularization term R(θ).L2 regularization is a quadratic function ofL2\\nregularization\\nthe weight values, named because it uses the (square of the) L2 norm of the weight\\nvalues. The L2 norm, ||θ||2, is the same as the Euclidean distance of the vector θ\\nfrom the origin. If θconsists of nweights, then:\\nR(θ) =||θ||2\\n2=n∑\\nj=1θ2\\nj (5.37)\\nThe L2 regularized objective function becomes:\\nˆθ=argmax\\nθ[m∑\\ni=1logP(y(i)|x(i))]\\n−αn∑\\nj=1θ2\\nj (5.38)\\nL1 regularization is a linear function of the weight values, named after the L1 normL1\\nregularization\\n||W||1, the sum of the absolute values of the weights, or Manhattan distance (the', metadata={'source': '/content/5.pdf', 'page': 18}),\n",
              " Document(page_content='20 CHAPTER 5 • L OGISTIC REGRESSION\\nManhattan distance is the distance you’d have to walk between two points in a city\\nwith a street grid like New York):\\nR(θ) =||θ||1=n∑\\ni=1|θi| (5.39)\\nThe L1 regularized objective function becomes:\\nˆθ=argmax\\nθ[m∑\\ni=1logP(y(i)|x(i))]\\n−αn∑\\nj=1|θj| (5.40)\\nThese kinds of regularization come from statistics, where L1 regularization is called\\nlasso regression (Tibshirani, 1996) and L2 regularization is called ridge regression , lasso\\nridge and both are commonly used in language processing. L2 regularization is easier to\\noptimize because of its simple derivative (the derivative of θ2is just 2 θ), while\\nL1 regularization is more complex (the derivative of |θ|is non-continuous at zero).\\nBut while L2 prefers weight vectors with many small weights, L1 prefers sparse\\nsolutions with some larger weights but many more weights set to zero. Thus L1\\nregularization leads to much sparser weight vectors, that is, far fewer features.\\nBoth L1 and L2 regularization have Bayesian interpretations as constraints on\\nthe prior of how weights should look. L1 regularization can be viewed as a Laplace\\nprior on the weights. L2 regularization corresponds to assuming that weights are\\ndistributed according to a Gaussian distribution with mean µ=0. In a Gaussian\\nor normal distribution, the further away a value is from the mean, the lower its\\nprobability (scaled by the variance σ). By using a Gaussian prior on the weights, we\\nare saying that weights prefer to have the value 0. A Gaussian for a weight θjis\\n1√\\n2πσ2\\njexp(\\n−(θj−µj)2\\n2σ2\\nj)\\n(5.41)\\nIf we multiply each weight by a Gaussian prior on the weight, we are thus maximiz-\\ning the following constraint:\\nˆθ=argmax\\nθm∏\\ni=1P(y(i)|x(i))×n∏\\nj=11√\\n2πσ2\\njexp(\\n−(θj−µj)2\\n2σ2\\nj)\\n(5.42)\\nwhich in log space, with µ=0, and assuming 2 σ2=1, corresponds to\\nˆθ=argmax\\nθm∑\\ni=1logP(y(i)|x(i))−αn∑\\nj=1θ2\\nj (5.43)\\nwhich is in the same form as Eq. 5.38.\\n5.8 Learning in Multinomial Logistic Regression\\nThe loss function for multinomial logistic regression generalizes the loss function\\nfor binary logistic regression from 2 to Kclasses. Recall that that the cross-entropy\\nloss for binary logistic regression (repeated from Eq. 5.23) is:\\nLCE(ˆy,y) =−logp(y|x) =−[ylog ˆy+(1−y)log(1−ˆy)] (5.44)', metadata={'source': '/content/5.pdf', 'page': 19}),\n",
              " Document(page_content='5.8 • L EARNING IN MULTINOMIAL LOGISTIC REGRESSION 21\\nThe loss function for multinomial logistic regression generalizes the two terms in\\nEq. 5.44 (one that is non-zero when y=1 and one that is non-zero when y=0) to\\nKterms. As we mentioned above, for multinomial regression we’ll represent both y\\nandˆyas vectors. The true label yis a vector with Kelements, each corresponding\\nto a class, with yc=1 if the correct class is c, with all other elements of ybeing 0.\\nAnd our classiﬁer will produce an estimate vector with Kelements ˆy, each element\\nˆykof which represents the estimated probability p(yk=1|x).\\nThe loss function for a single example x, generalizing from binary logistic re-\\ngression, is the sum of the logs of the Koutput classes, each weighted by their\\nprobability yk(Eq. 5.45). This turns out to be just the negative log probability of the\\ncorrect class c(Eq. 5.46):\\nLCE(ˆy,y) =−K∑\\nk=1yklog ˆyk (5.45)\\n=−log ˆyc,(where cis the correct class) (5.46)\\n=−log ˆp(yc=1|x)(where cis the correct class)\\n=−logexp(wc·x+bc)∑K\\nj=1exp(wj·x+bj)(cis the correct class) (5.47)\\nHow did we get from Eq. 5.45 to Eq. 5.46? Because only one class (let’s call it c) is\\nthe correct one, the vector ytakes the value 1 only for this value of k, i.e., has yc=1\\nandyj=0∀j̸=c. That means the terms in the sum in Eq. 5.45 will all be 0 except\\nfor the term corresponding to the true class c. Hence the cross-entropy loss is simply\\nthe log of the output probability corresponding to the correct class, and we therefore\\nalso call Eq. 5.46 the negative log likelihood loss .negative log\\nlikelihood loss\\nOf course for gradient descent we don’t need the loss, we need its gradient. The\\ngradient for a single example turns out to be very similar to the gradient for binary\\nlogistic regression, (ˆy−y)x, that we saw in Eq. 5.30. Let’s consider one piece of the\\ngradient, the derivative for a single weight. For each class k, the weight of the ith\\nelement of input xiswk,i. What is the partial derivative of the loss with respect to\\nwk,i? This derivative turns out to be just the difference between the true value for the\\nclass k(which is either 1 or 0) and the probability the classiﬁer outputs for class k,\\nweighted by the value of the input xicorresponding to the ith element of the weight\\nvector for class k:\\n∂LCE\\n∂wk,i=−(yk−ˆyk)xi\\n=−(yk−p(yk=1|x))xi\\n=−(\\nyk−exp(wk·x+bk)∑K\\nj=1exp(wj·x+bj))\\nxi (5.48)\\nWe’ll return to this case of the gradient for softmax regression when we introduce\\nneural networks in Chapter 7, and at that time we’ll also discuss the derivation of\\nthis gradient in equations Eq. ??–Eq. ??.', metadata={'source': '/content/5.pdf', 'page': 20}),\n",
              " Document(page_content='22 CHAPTER 5 • L OGISTIC REGRESSION\\n5.9 Interpreting models\\nOften we want to know more than just the correct classiﬁcation of an observation.\\nWe want to know why the classiﬁer made the decision it did. That is, we want our\\ndecision to be interpretable . Interpretability can be hard to deﬁne strictly, but the interpretable\\ncore idea is that as humans we should know why our algorithms reach the conclu-\\nsions they do. Because the features to logistic regression are often human-designed,\\none way to understand a classiﬁer’s decision is to understand the role each feature\\nplays in the decision. Logistic regression can be combined with statistical tests (the\\nlikelihood ratio test, or the Wald test); investigating whether a particular feature is\\nsigniﬁcant by one of these tests, or inspecting its magnitude (how large is the weight\\nwassociated with the feature?) can help us interpret why the classiﬁer made the\\ndecision it makes. This is enormously important for building transparent models.\\nFurthermore, in addition to its use as a classiﬁer, logistic regression in NLP and\\nmany other ﬁelds is widely used as an analytic tool for testing hypotheses about the\\neffect of various explanatory variables (features). In text classiﬁcation, perhaps we\\nwant to know if logically negative words ( no, not, never ) are more likely to be asso-\\nciated with negative sentiment, or if negative reviews of movies are more likely to\\ndiscuss the cinematography. However, in doing so it’s necessary to control for po-\\ntential confounds: other factors that might inﬂuence sentiment (the movie genre, the\\nyear it was made, perhaps the length of the review in words). Or we might be study-\\ning the relationship between NLP-extracted linguistic features and non-linguistic\\noutcomes (hospital readmissions, political outcomes, or product sales), but need to\\ncontrol for confounds (the age of the patient, the county of voting, the brand of the\\nproduct). In such cases, logistic regression allows us to test whether some feature is\\nassociated with some outcome above and beyond the effect of other features.\\n5.10 Advanced: Deriving the Gradient Equation\\nIn this section we give the derivation of the gradient of the cross-entropy loss func-\\ntion LCEfor logistic regression. Let’s start with some quick calculus refreshers.\\nFirst, the derivative of ln (x):\\nd\\ndxln(x) =1\\nx(5.49)\\nSecond, the (very elegant) derivative of the sigmoid:\\ndσ(z)\\ndz=σ(z)(1−σ(z)) (5.50)\\nFinally, the chain rule of derivatives. Suppose we are computing the derivative chain rule\\nof a composite function f(x) =u(v(x)). The derivative of f(x)is the derivative of\\nu(x)with respect to v(x)times the derivative of v(x)with respect to x:\\nd f\\ndx=du\\ndv·dv\\ndx(5.51)\\nFirst, we want to know the derivative of the loss function with respect to a single\\nweight wj(we’ll need to compute it for each weight, and for the bias):', metadata={'source': '/content/5.pdf', 'page': 21}),\n",
              " Document(page_content='5.11 • S UMMARY 23\\n∂LCE\\n∂wj=∂\\n∂wj−[ylogσ(w·x+b)+(1−y)log(1−σ(w·x+b))]\\n=−[∂\\n∂wjylogσ(w·x+b)+∂\\n∂wj(1−y)log[1−σ(w·x+b)]]\\n(5.52)\\nNext, using the chain rule, and relying on the derivative of log:\\n∂LCE\\n∂wj=−y\\nσ(w·x+b)∂\\n∂wjσ(w·x+b)−1−y\\n1−σ(w·x+b)∂\\n∂wj1−σ(w·x+b)\\n(5.53)\\nRearranging terms:\\n∂LCE\\n∂wj=−[y\\nσ(w·x+b)−1−y\\n1−σ(w·x+b)]∂\\n∂wjσ(w·x+b)\\n(5.54)\\nAnd now plugging in the derivative of the sigmoid, and using the chain rule one\\nmore time, we end up with Eq. 5.55:\\n∂LCE\\n∂wj=−[y−σ(w·x+b)\\nσ(w·x+b)[1−σ(w·x+b)]]\\nσ(w·x+b)[1−σ(w·x+b)]∂(w·x+b)\\n∂wj\\n=−[y−σ(w·x+b)\\nσ(w·x+b)[1−σ(w·x+b)]]\\nσ(w·x+b)[1−σ(w·x+b)]xj\\n=−[y−σ(w·x+b)]xj\\n= [σ(w·x+b)−y]xj (5.55)\\n5.11 Summary\\nThis chapter introduced the logistic regression model of classiﬁcation .\\n• Logistic regression is a supervised machine learning classiﬁer that extracts\\nreal-valued features from the input, multiplies each by a weight, sums them,\\nand passes the sum through a sigmoid function to generate a probability. A\\nthreshold is used to make a decision.\\n• Logistic regression can be used with two classes (e.g., positive and negative\\nsentiment) or with multiple classes ( multinomial logistic regression , for ex-\\nample for n-ary text classiﬁcation, part-of-speech labeling, etc.).\\n• Multinomial logistic regression uses the softmax function to compute proba-\\nbilities.\\n• The weights (vector wand bias b) are learned from a labeled training set via a\\nloss function, such as the cross-entropy loss , that must be minimized.\\n• Minimizing this loss function is a convex optimization problem, and iterative\\nalgorithms like gradient descent are used to ﬁnd the optimal weights.\\n•Regularization is used to avoid overﬁtting.\\n• Logistic regression is also one of the most useful analytic tools, because of its\\nability to transparently study the importance of individual features.', metadata={'source': '/content/5.pdf', 'page': 22}),\n",
              " Document(page_content='24 CHAPTER 5 • L OGISTIC REGRESSION\\nBibliographical and Historical Notes\\nLogistic regression was developed in the ﬁeld of statistics, where it was used for\\nthe analysis of binary data by the 1960s, and was particularly common in medicine\\n(Cox, 1969). Starting in the late 1970s it became widely used in linguistics as one\\nof the formal foundations of the study of linguistic variation (Sankoff and Labov,\\n1979).\\nNonetheless, logistic regression didn’t become common in natural language pro-\\ncessing until the 1990s, when it seems to have appeared simultaneously from two\\ndirections. The ﬁrst source was the neighboring ﬁelds of information retrieval and\\nspeech processing, both of which had made use of regression, and both of which\\nlent many other statistical techniques to NLP. Indeed a very early use of logistic\\nregression for document routing was one of the ﬁrst NLP applications to use (LSI)\\nembeddings as word representations (Sch ¨utze et al., 1995).\\nAt the same time in the early 1990s logistic regression was developed and ap-\\nplied to NLP at IBM Research under the name maximum entropy modeling ormaximum\\nentropy\\nmaxent (Berger et al., 1996), seemingly independent of the statistical literature. Un-\\nder that name it was applied to language modeling (Rosenfeld, 1996), part-of-speech\\ntagging (Ratnaparkhi, 1996), parsing (Ratnaparkhi, 1997), coreference resolution\\n(Kehler, 1997), and text classiﬁcation (Nigam et al., 1999).\\nMore on classiﬁcation can be found in machine learning textbooks (Hastie et al.\\n2001, Witten and Frank 2005, Bishop 2006, Murphy 2012).\\nExercises', metadata={'source': '/content/5.pdf', 'page': 23}),\n",
              " Document(page_content='Exercises 25\\nBerger, A., S. A. Della Pietra, and V . J. Della Pietra. 1996. A\\nmaximum entropy approach to natural language process-\\ning. Computational Linguistics , 22(1):39–71.\\nBishop, C. M. 2006. Pattern recognition and machine learn-\\ning. Springer.\\nCox, D. 1969. Analysis of Binary Data . Chapman and Hall,\\nLondon.\\nHastie, T., R. J. Tibshirani, and J. H. Friedman. 2001. The\\nElements of Statistical Learning . Springer.\\nKehler, A. 1997. Probabilistic coreference in information\\nextraction. EMNLP .\\nMurphy, K. P. 2012. Machine learning: A probabilistic per-\\nspective . MIT Press.\\nNg, A. Y . and M. I. Jordan. 2002. On discriminative vs.\\ngenerative classiﬁers: A comparison of logistic regres-\\nsion and naive bayes. NeurIPS .\\nNigam, K., J. D. Lafferty, and A. McCallum. 1999. Using\\nmaximum entropy for text classiﬁcation. IJCAI-99 work-\\nshop on machine learning for information ﬁltering .\\nRatnaparkhi, A. 1996. A maximum entropy part-of-speech\\ntagger. EMNLP .\\nRatnaparkhi, A. 1997. A linear observed time statistical\\nparser based on maximum entropy models. EMNLP .\\nRosenfeld, R. 1996. A maximum entropy approach to adap-\\ntive statistical language modeling. Computer Speech and\\nLanguage , 10:187–228.\\nSankoff, D. and W. Labov. 1979. On the uses of variable\\nrules. Language in society , 8(2-3):189–222.\\nSch¨utze, H., D. A. Hull, and J. Pedersen. 1995. A compar-\\nison of classiﬁers and document representations for the\\nrouting problem. SIGIR-95 .\\nTibshirani, R. J. 1996. Regression shrinkage and selection\\nvia the lasso. Journal of the Royal Statistical Society. Se-\\nries B (Methodological) , 58(1):267–288.\\nWang, S. and C. D. Manning. 2012. Baselines and bigrams:\\nSimple, good sentiment and topic classiﬁcation. ACL.\\nWitten, I. H. and E. Frank. 2005. Data Mining: Practi-\\ncal Machine Learning Tools and Techniques , 2nd edition.\\nMorgan Kaufmann.', metadata={'source': '/content/5.pdf', 'page': 24})]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 4: Split the Text into Chunks**"
      ],
      "metadata": {
        "id": "68n73kgaYcl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)"
      ],
      "metadata": {
        "id": "Tz3q1oCgYPye"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs=text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "9kqT_CZVYr1Q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ejpwUSmYx27",
        "outputId": "0fcdc150-e2e6-49b0-ec41-5690fefac889"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "142"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp9fEipegFuZ",
        "outputId": "ec9d452b-f478-4e9f-cff5-4d607041f254"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Speech and Language Processing. Daniel Jurafsky & James H. Martin. Copyright ©2023. All\\nrights reserved. Draft of February 3, 2024.\\nCHAPTER\\n5Logistic Regression\\n“And how do you know that these ﬁne begonias are not of equal importance?”\\nHercule Poirot, in Agatha Christie’s The Mysterious Affair at Styles\\nDetective stories are as littered with clues as texts are with words. Yet for the\\npoor reader it can be challenging to know how to weigh the author’s clues in order', metadata={'source': '/content/5.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 5: Setup the Environment**"
      ],
      "metadata": {
        "id": "K24-STW9ZGnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
        "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY', 'bf23525e-cab7-4059-b552-e04d1b912134')\n",
        "PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', 'gcp-starter')"
      ],
      "metadata": {
        "id": "aZMYGbDlY1pL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 6: Downlaod the Embeddings**"
      ],
      "metadata": {
        "id": "waQtomfxZhM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "_937693LZpoY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473,
          "referenced_widgets": [
            "65b358f7355e479199d008b7fccf40d9",
            "d33d0f0a61a243c2882d222cddfc6732",
            "c679cac6e61c4289b81560dc3fc66c20",
            "169fde6b280241098d28c45685be1805",
            "20341f667aed49f8943697da2729ee0b",
            "a01ccf2bb5754d2390e88b9e21aa25cf",
            "db1fa26730ec400a8d2aff032ca08f5a",
            "a0c35d82a2f649b2863c9b83e1949340",
            "28628ccd19fa4016834f9e61cc137d8e",
            "3b339c7a962d429c9f6eab7239324a0e",
            "ed4bb05a2a6747adb50df234ae04df79",
            "0221851a2a224f1faeebc68319dc1c02",
            "84a5174c6fab48a7b8d1353328a1e6b9",
            "78fe88dfaf524bbf8fbae7ba6fd62df0",
            "5504a3838bc74d2c85d8fc1fe2a6054e",
            "b623189b0191471087df68fa96695db9",
            "b09f062f7ae242cdb7b548cd8c5e1d01",
            "282d6dffdff448eb93282b5561a01b32",
            "fd3b6d6b2866450489d73e0df990b979",
            "c7aabca8ac9f45e486a7c00ef07742f1",
            "5c622b1ec8664a15a999b33c1d2ba95a",
            "04f44a1d74c74358b71aa1433deadd9a",
            "c44c73bf6c56491fb52e411817c68ccc",
            "adf38f5ac91642869da939843e33eb85",
            "fee64dcf825f4782abe3312d389b98a9",
            "2607247ce083405e84e1a0c0b621992d",
            "6861d1f131554f7a9c28c673a75b9924",
            "5952cba1275345eeaa2f1f7ef2a69fca",
            "8ae46e617df8460288bd81ec2fcb386e",
            "d09e66b6b86c46efb9b37d24df9434f8",
            "7caff54ac3504713969586a0e7594764",
            "5001e02e5153482e9b7382aa7b0b026c",
            "ff9030a329d14f7a9e174ee3f2cde6a6",
            "582e610b38c3402faca432105fb5712a",
            "f81caa54ab74430cbddf9caf52b34534",
            "932be7d3dbcd46cfa72fa7d11c4d6343",
            "fdf009e9bc66449b8d41b8693efcbf5f",
            "a9e4b0e4f1534036951a15909a9046da",
            "1cb554a5bdef4f48937ab3e4219e7864",
            "7a97a99e686e49bf8fc2d51a4428b29e",
            "04f39585638c46d6b921bc1ef71e1d2d",
            "72ef9874d1464de7a4260eec342259e8",
            "a082253244aa4008a42d9431dac785c0",
            "c8d6f69ad85b4a218ea7841f44ee928e",
            "25d43ba9f75047c19ccbb994e646bd97",
            "63e79626f8c84b8bb31c37a5b2474812",
            "add720e2551e4ddb9e047d3e02dc3ba7",
            "bf1b25103e8045ebbf8ef4bab1da0dbb",
            "13b51f2be44541b2bb43a943ff4e4b21",
            "1ed6da40c8f24404be9c2ad58a00d95a",
            "c89d6a29aa6d4cd48d327905f6cd2060",
            "18e081b4cdfe4c58a36a5af3f72d9e25",
            "b10e789392894253831984c5ff327dc2",
            "fda11be261de4550a3b514e057b3e99d",
            "8fb98ef096974fdd864fa56db42d3730",
            "d39942ee213849409e6992888d029e9f",
            "b936bc30dddd4f86944a1a1ea70152ff",
            "d46730d42da14f818639f913f8fb915e",
            "1c12f8bf01a3421380b888a429d4535b",
            "bd8ef83e3b2d4793a2976410c475cedc",
            "0043e51038794784995fb018ba124b95",
            "1acb1ef952d7411fa5187c455d38b3a7",
            "b6d7161a7b6c4cacadfa97cac0189e39",
            "1acdeebee00a42fd9ceecda71dd8a19b",
            "9ef43f669829492b9eb86c0114e8393f",
            "afe9d4891f1046e8905d6acc6f83229b",
            "5448d3d34fa2476986d968b9bd38cc57",
            "d830211330cf4c3fae49d62953e7dcc0",
            "3c5c2b48efb94f9da1051a819d8ee386",
            "f80f6e77ebc445c799d66aebdff2e90d",
            "73570070008244e89f16ded503a45153",
            "d393d3ef4aed4b35a10dd2cfe54f0725",
            "d9aeb9d9f93e4571a864c1ac73f0c037",
            "a6730cd11be04aeb830c4be895ac8723",
            "fa9f43f5a22a43d082f2a115c82cf484",
            "2f4eb85b2a804209ad5ae5da382a37a6",
            "bc5c1f75031642248519eff14c0acd93",
            "6fdee25b75d44949b60babfc27787b14",
            "2fd8c24b1aa943d9a418f3d6f55461f5",
            "feace6e6b92247b4bae51f177a66116b",
            "668415a1f7eb43829fce1adaa79d5f52",
            "d61a949b3afb4289a8b9cae64c12d363",
            "ecc64df45cbd42558f8da8b2bf3f3058",
            "651060d70ff4462ea16287a34675adae",
            "a5817d4dda9041d78a4f7ac17860d480",
            "c6d15e718f96401bac06feb8b71b3cef",
            "dffb5c8660ba44c6a4a6e8edfd43ed5e",
            "7e7c556e75d4407493bb75014e21af0a",
            "ab2d7b4f21de4592b23d869b933c6cc9",
            "3ada3828a18746f893ccdc2e3f5efb49",
            "5e22719e87d64288aab5b8c4ae61f9bc",
            "b6fb4a1acae640af97030fe0592b3809",
            "85bf9c1acdd14fe0a02e6c1ceea0baec",
            "c9132e3fa0c044c89416f06530209420",
            "6cfa8ab66dcc433f904335fd836cbe81",
            "d0d7ca3634054e1dab9c6589bc30c048",
            "b85b30dcada045cd9e586b45a899b429",
            "c8abaf9377774ae3858b66848c32eb0f",
            "18af0940cff240a8b4192502b64515de",
            "98de905ecc1e4b0680ee0a6acba981c5",
            "4fcd2200a0474eab886a3f5f27a57d54",
            "e67b6256deca4a3aa4d7c8a8534b7016",
            "3e813da9edcc4dba922f826fad6a029d",
            "bdb2ddc2ebc147c7a5ab40dba7d836f6",
            "1111bcdd2a4649de830fd5d8abdf63ec",
            "a9a65ea1392c4c1e927fdeda216e4ef2",
            "0defddce5e1a43fba8c940ee3195e5c3",
            "4721d3b2b4eb4e509711e006315dc937",
            "0e8331cd56b34a2b89a9e64191e60043",
            "5c301d90ca6c46d4a70150150d0874ea",
            "b81785468c91433499e08e85ed4877af",
            "069d1d2d09694f81bb852d2e25db6937",
            "4599932db48b46fab51d36fa6e7a35a5",
            "069e6f1b25dc4be5a152d0929febdbff",
            "cde0a7f4d3884773a40dbca73e7ce678",
            "667879cfbf4c4a8781fdc6f8c7eebc5a",
            "d7529fcf5a3f4db8a06750723cd062d0",
            "1c7c173b84904335b066663d6fe2f783",
            "c12e3b08eeb3474894a548e8df268d39",
            "c7ee3de1ee1246b5b2977c8e7273c309",
            "95b0a3593bb34066a3261bf85e34abb0"
          ]
        },
        "outputId": "eb1d0fa8-33a2-4ab1-a582-1f0ee930331f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65b358f7355e479199d008b7fccf40d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0221851a2a224f1faeebc68319dc1c02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c44c73bf6c56491fb52e411817c68ccc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "582e610b38c3402faca432105fb5712a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25d43ba9f75047c19ccbb994e646bd97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d39942ee213849409e6992888d029e9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5448d3d34fa2476986d968b9bd38cc57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fdee25b75d44949b60babfc27787b14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab2d7b4f21de4592b23d869b933c6cc9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98de905ecc1e4b0680ee0a6acba981c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b81785468c91433499e08e85ed4877af"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 7: Initializing the Pinecone**"
      ],
      "metadata": {
        "id": "a9pCsYXaaL6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install \"pinecone-client[grpc]\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAy-ORgrQsQR",
        "outputId": "0cbbec8e-1b2d-4175-9813-ab6c46dde5db"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone-client[grpc] in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client[grpc]) (2024.2.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client[grpc]) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client[grpc]) (4.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client[grpc]) (1.26.18)\n",
            "Requirement already satisfied: googleapis-common-protos>=1.53.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client[grpc]) (1.63.0)\n",
            "Collecting grpc-gateway-protoc-gen-openapiv2==0.1.0 (from pinecone-client[grpc])\n",
            "  Downloading grpc_gateway_protoc_gen_openapiv2-0.1.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: grpcio>=1.44.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client[grpc]) (1.62.1)\n",
            "Collecting lz4>=3.1.3 (from pinecone-client[grpc])\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<3.21.0,>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client[grpc]) (3.20.3)\n",
            "Installing collected packages: lz4, grpc-gateway-protoc-gen-openapiv2\n",
            "Successfully installed grpc-gateway-protoc-gen-openapiv2-0.1.0 lz4-4.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load api key as env variable\n",
        "api_key = \"64fa4ca1-03da-4967-90fa-991fabc4f4c4\"\n",
        "\n",
        "os.environ[\"PINECONE_API_KEY\"] = api_key\n",
        "\n",
        "# create instance of pinecone\n",
        "from pinecone import Pinecone\n",
        "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))"
      ],
      "metadata": {
        "id": "5wQMhp6LQRXh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize pinecone\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
        "    environment=PINECONE_API_ENV  # next to api key in console\n",
        ")\n",
        "index_name = \"langchainpinecone\" # put in the name of your pinecone index here"
      ],
      "metadata": {
        "id": "7vYf3XVZZ0eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 8: Create Embeddings for Each of the Text Chunk**"
      ],
      "metadata": {
        "id": "BAAiFNyoawX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Pinecone as PC\n",
        "# import Pinecone from langchain as the latest pinecone doesn't have from_text function\n",
        "\n",
        "\n",
        "\n",
        "index_name = 'langchainpinecone'\n",
        "docsearch=PC.from_texts([t.page_content for t in docs], embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "aPTbec-ea1r8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# If you already have an index, you can load it like this\n"
      ],
      "metadata": {
        "id": "amB5Se8cs3zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#docsearch = Pinecone.from_existing_index(index_name, embeddings)\n"
      ],
      "metadata": {
        "id": "ewMdzQFGs16I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 9: Similarity Search**"
      ],
      "metadata": {
        "id": "mQbKwQZubUI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#query=\"What are examples of good data science teams?\"\n",
        "query=\"what is loss function of logistic regression?\""
      ],
      "metadata": {
        "id": "SrXpO0ecbSWb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs=docsearch.similarity_search(query, k=1)"
      ],
      "metadata": {
        "id": "BDxlZIn-bbQY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lXRzM-XbqHU",
        "outputId": "9c57e1ac-ede7-4c7b-d750-e9a2d0a2b6b1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='For logistic regression, this loss function is conveniently convex . A convex func- convex\\ntion has at most one minimum; there are no local minima to get stuck in, so gradient\\ndescent starting from any point is guaranteed to ﬁnd the minimum. (By contrast,\\nthe loss for multi-layer neural networks is non-convex, and gradient descent may\\nget stuck in local minima for neural network training and never ﬁnd the global opti-\\nmum.)')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 9: Query the Docs to get the Answer Back (Llama 2 Model)**"
      ],
      "metadata": {
        "id": "SlcdYpG2rlRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using quantized version(memory efficient by trading precision) to run it on colab and local system."
      ],
      "metadata": {
        "id": "_OVhVzztaCrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir --verbose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qLilW73vIby",
        "outputId": "2626fd48-2c66-4cbf-8058-34f317d48fe1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.57.tar.gz (36.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.9/36.9 MB\u001b[0m \u001b[31m167.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Running command pip subprocess to install build dependencies\n",
            "  Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "  Collecting scikit-build-core[pyproject]>=0.5.1\n",
            "    Using cached scikit_build_core-0.8.2-py3-none-any.whl (140 kB)\n",
            "  Collecting exceptiongroup (from scikit-build-core[pyproject]>=0.5.1)\n",
            "    Using cached exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
            "  Collecting packaging>=20.9 (from scikit-build-core[pyproject]>=0.5.1)\n",
            "    Using cached packaging-24.0-py3-none-any.whl (53 kB)\n",
            "  Collecting tomli>=1.1 (from scikit-build-core[pyproject]>=0.5.1)\n",
            "    Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "  Collecting pathspec>=0.10.1 (from scikit-build-core[pyproject]>=0.5.1)\n",
            "    Using cached pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "  Collecting pyproject-metadata>=0.5 (from scikit-build-core[pyproject]>=0.5.1)\n",
            "    Using cached pyproject_metadata-0.7.1-py3-none-any.whl (7.4 kB)\n",
            "  Installing collected packages: tomli, pathspec, packaging, exceptiongroup, scikit-build-core, pyproject-metadata\n",
            "  ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "  langchain-core 0.1.33 requires packaging<24.0,>=23.2, but you have packaging 24.0 which is incompatible.\n",
            "  plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "  tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
            "  tensorflow 2.15.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.16.0 which is incompatible.\n",
            "  unstructured 0.12.6 requires numpy==1.26.4, but you have numpy 1.22.4 which is incompatible.\n",
            "  unstructured 0.12.6 requires packaging==23.2, but you have packaging 24.0 which is incompatible.\n",
            "  Successfully installed exceptiongroup-1.2.0 packaging-24.0 pathspec-0.12.1 pyproject-metadata-0.7.1 scikit-build-core-0.8.2 tomli-2.0.1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Getting requirements to build wheel\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command pip subprocess to install backend dependencies\n",
            "  Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "  Collecting cmake>=3.21\n",
            "    Using cached cmake-3.28.4-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n",
            "  Collecting ninja>=1.5\n",
            "    Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "  Installing collected packages: ninja, cmake\n",
            "    Creating /tmp/pip-build-env-8y3d1y65/normal/local/bin\n",
            "    changing mode of /tmp/pip-build-env-8y3d1y65/normal/local/bin/ninja to 755\n",
            "    changing mode of /tmp/pip-build-env-8y3d1y65/normal/local/bin/cmake to 755\n",
            "    changing mode of /tmp/pip-build-env-8y3d1y65/normal/local/bin/cpack to 755\n",
            "    changing mode of /tmp/pip-build-env-8y3d1y65/normal/local/bin/ctest to 755\n",
            "  Successfully installed cmake-3.28.4 ninja-1.11.1.1\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Preparing metadata (pyproject.toml)\n",
            "  *** scikit-build-core 0.8.2 using CMake 3.28.4 (metadata_wheel)\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting typing-extensions>=4.5.0 (from llama-cpp-python)\n",
            "  Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
            "Collecting numpy>=1.20.0 (from llama-cpp-python)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m313.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m250.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2>=2.11.3 (from llama-cpp-python)\n",
            "  Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m298.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Running command Building wheel for llama-cpp-python (pyproject.toml)\n",
            "  *** scikit-build-core 0.8.2 using CMake 3.28.4 (wheel)\n",
            "  *** Configuring CMake...\n",
            "  loading initial cache file /tmp/tmpq7pj35f3/build/CMakeInit.txt\n",
            "  -- The C compiler identification is GNU 11.4.0\n",
            "  -- The CXX compiler identification is GNU 11.4.0\n",
            "  -- Detecting C compiler ABI info\n",
            "  -- Detecting C compiler ABI info - done\n",
            "  -- Check for working C compiler: /usr/bin/cc - skipped\n",
            "  -- Detecting C compile features\n",
            "  -- Detecting C compile features - done\n",
            "  -- Detecting CXX compiler ABI info\n",
            "  -- Detecting CXX compiler ABI info - done\n",
            "  -- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "  -- Detecting CXX compile features\n",
            "  -- Detecting CXX compile features - done\n",
            "  -- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "  -- Found Threads: TRUE\n",
            "  -- Found CUDAToolkit: /usr/local/cuda/targets/x86_64-linux/include (found version \"12.2.140\")\n",
            "  -- cuBLAS found\n",
            "  -- The CUDA compiler identification is NVIDIA 12.2.140\n",
            "  -- Detecting CUDA compiler ABI info\n",
            "  -- Detecting CUDA compiler ABI info - done\n",
            "  -- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "  -- Detecting CUDA compile features\n",
            "  -- Detecting CUDA compile features - done\n",
            "  -- Using CUDA architectures: 52;61;70\n",
            "  -- CUDA host compiler is GNU 11.4.0\n",
            "\n",
            "  -- Warning: ccache not found - consider installing it for faster compilation or disable this warning with LLAMA_CCACHE=OFF\n",
            "  -- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "  -- x86 detected\n",
            "  CMake Warning (dev) at CMakeLists.txt:21 (install):\n",
            "    Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n",
            "  This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\n",
            "  CMake Warning (dev) at CMakeLists.txt:30 (install):\n",
            "    Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n",
            "  This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\n",
            "  -- Configuring done (4.0s)\n",
            "  -- Generating done (0.0s)\n",
            "  -- Build files have been written to: /tmp/tmpq7pj35f3/build\n",
            "  *** Building project with Ninja...\n",
            "  Change Dir: '/tmp/tmpq7pj35f3/build'\n",
            "\n",
            "  Run Build Command(s): /tmp/pip-build-env-8y3d1y65/normal/local/lib/python3.10/dist-packages/ninja/data/bin/ninja -v\n",
            "  [1/24] /usr/bin/cc -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o -c /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/ggml-alloc.c\n",
            "  [2/24] /usr/bin/cc -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o -c /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/ggml-backend.c\n",
            "  [3/24] /usr/bin/cc -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o -c /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/ggml-quants.c\n",
            "  [4/24] /usr/bin/cc -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o -c /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/ggml.c\n",
            "  [5/24] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -DLLAMA_BUILD -DLLAMA_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dllama_EXPORTS -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/CMakeFiles/llama.dir/unicode.cpp.o -MF vendor/llama.cpp/CMakeFiles/llama.dir/unicode.cpp.o.d -o vendor/llama.cpp/CMakeFiles/llama.dir/unicode.cpp.o -c /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/unicode.cpp\n",
            "  [6/24] cd /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp && /tmp/pip-build-env-8y3d1y65/normal/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -DMSVC= -DCMAKE_C_COMPILER_VERSION=11.4.0 -DCMAKE_C_COMPILER_ID=GNU -DCMAKE_VS_PLATFORM_NAME= -DCMAKE_C_COMPILER=/usr/bin/cc -P /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/common/../scripts/gen-build-info-cpp.cmake\n",
            "  -- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "  [7/24] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600  -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o -c /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/common/build-info.cpp\n",
            "  [8/24] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/common/. -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o -c /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/common/common.cpp\n",
            "  [9/24] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/common/. -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o -c /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/common/sampling.cpp\n",
            "  [10/24] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/common/. -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o -c /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/common/console.cpp\n",
            "  [11/24] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/common/. -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o -c /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/common/grammar-parser.cpp\n",
            "  [12/24] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/common/. -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o -c /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/common/train.cpp\n",
            "  [13/24] /usr/bin/c++ -DGGML_USE_CUBLAS -DLLAMA_BUILD -DLLAMA_SHARED -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/examples/llava/../../common -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -fPIC -Wno-cast-qual -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o -c /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/examples/llava/llava.cpp\n",
            "  [14/24] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -DLLAMA_BUILD -DLLAMA_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dllama_EXPORTS -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o -MF vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o.d -o vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o -c /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/llama.cpp\n",
            "  [15/24] /usr/bin/c++ -DGGML_USE_CUBLAS -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/common/. -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/. -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/examples/llava/../../common -O3 -DNDEBUG -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -c /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/examples/llava/llava-cli.cpp\n",
            "  [16/24] /usr/bin/c++ -DGGML_USE_CUBLAS -DLLAMA_BUILD -DLLAMA_SHARED -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/examples/llava/../../common -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -fPIC -Wno-cast-qual -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o -c /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/examples/llava/clip.cpp\n",
            "  [17/24] : && /tmp/pip-build-env-8y3d1y65/normal/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E rm -f vendor/llama.cpp/examples/llava/libllava_static.a && /usr/bin/ar qc vendor/llama.cpp/examples/llava/libllava_static.a  vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o && /usr/bin/ranlib vendor/llama.cpp/examples/llava/libllava_static.a && :\n",
            "  [18/24] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUBLAS -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o.d -x cu -c /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/vendor/llama.cpp/ggml-cuda.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o\n",
            "  [19/24] : && /usr/bin/c++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libllama.so -o vendor/llama.cpp/libllama.so vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o vendor/llama.cpp/CMakeFiles/llama.dir/unicode.cpp.o -L/usr/local/cuda/targets/x86_64-linux/lib -Wl,-rpath,/usr/local/cuda-12.2/targets/x86_64-linux/lib:  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcudart.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcublas.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcublasLt.so  /usr/local/cuda/targets/x86_64-linux/lib/stubs/libcuda.so  -ldl  /usr/lib/x86_64-linux-gnu/librt.a  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libculibos.a  -lcudadevrt  -lcudart_static  -lrt  -lpthread  -ldl && :\n",
            "  [20/24] : && /tmp/pip-build-env-8y3d1y65/normal/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E rm -f vendor/llama.cpp/libggml_static.a && /usr/bin/ar qc vendor/llama.cpp/libggml_static.a  vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o && /usr/bin/ranlib vendor/llama.cpp/libggml_static.a && :\n",
            "  [21/24] : && /usr/bin/g++ -fPIC  -shared -Wl,-soname,libggml_shared.so -o vendor/llama.cpp/libggml_shared.so vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcudart.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcublas.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcublasLt.so  /usr/local/cuda/targets/x86_64-linux/lib/stubs/libcuda.so  -ldl  /usr/lib/x86_64-linux-gnu/librt.a  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libculibos.a  -lcudadevrt  -lcudart_static  -lrt  -lpthread  -ldl -L\"/usr/local/cuda/targets/x86_64-linux/lib/stubs\" -L\"/usr/local/cuda/targets/x86_64-linux/lib\" && :\n",
            "  [22/24] : && /tmp/pip-build-env-8y3d1y65/normal/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E rm -f vendor/llama.cpp/common/libcommon.a && /usr/bin/ar qc vendor/llama.cpp/common/libcommon.a  vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o && /usr/bin/ranlib vendor/llama.cpp/common/libcommon.a && :\n",
            "  [23/24] : && /usr/bin/c++ -O3 -DNDEBUG  vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -o vendor/llama.cpp/examples/llava/llava-cli  -Wl,-rpath,/tmp/tmpq7pj35f3/build/vendor/llama.cpp:/usr/local/cuda-12.2/targets/x86_64-linux/lib:  vendor/llama.cpp/common/libcommon.a  vendor/llama.cpp/libllama.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcudart.so  -ldl  /usr/lib/x86_64-linux-gnu/librt.a  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcublas.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libculibos.a  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcublasLt.so  /usr/local/cuda/targets/x86_64-linux/lib/stubs/libcuda.so && :\n",
            "  [24/24] : && /usr/bin/c++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libllava.so -o vendor/llama.cpp/examples/llava/libllava.so vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o  -Wl,-rpath,/tmp/tmpq7pj35f3/build/vendor/llama.cpp:/usr/local/cuda-12.2/targets/x86_64-linux/lib:  vendor/llama.cpp/libllama.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcudart.so  -ldl  /usr/lib/x86_64-linux-gnu/librt.a  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcublas.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libculibos.a  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcublasLt.so  /usr/local/cuda/targets/x86_64-linux/lib/stubs/libcuda.so && :\n",
            "\n",
            "  *** Installing project into wheel...\n",
            "  -- Install configuration: \"Release\"\n",
            "  -- Installing: /tmp/tmpq7pj35f3/wheel/platlib/lib/libggml_shared.so\n",
            "  -- Installing: /tmp/tmpq7pj35f3/wheel/platlib/lib/cmake/Llama/LlamaConfig.cmake\n",
            "  -- Installing: /tmp/tmpq7pj35f3/wheel/platlib/lib/cmake/Llama/LlamaConfigVersion.cmake\n",
            "  -- Installing: /tmp/tmpq7pj35f3/wheel/platlib/include/ggml.h\n",
            "  -- Installing: /tmp/tmpq7pj35f3/wheel/platlib/include/ggml-alloc.h\n",
            "  -- Installing: /tmp/tmpq7pj35f3/wheel/platlib/include/ggml-backend.h\n",
            "  -- Installing: /tmp/tmpq7pj35f3/wheel/platlib/include/ggml-cuda.h\n",
            "  -- Installing: /tmp/tmpq7pj35f3/wheel/platlib/lib/libllama.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/tmpq7pj35f3/wheel/platlib/lib/libllama.so\" to \"\"\n",
            "  -- Installing: /tmp/tmpq7pj35f3/wheel/platlib/include/llama.h\n",
            "  -- Installing: /tmp/tmpq7pj35f3/wheel/platlib/bin/convert.py\n",
            "  -- Installing: /tmp/tmpq7pj35f3/wheel/platlib/bin/convert-lora-to-ggml.py\n",
            "  -- Installing: /tmp/tmpq7pj35f3/wheel/platlib/llama_cpp/libllama.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/tmpq7pj35f3/wheel/platlib/llama_cpp/libllama.so\" to \"\"\n",
            "  -- Installing: /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/llama_cpp/libllama.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/llama_cpp/libllama.so\" to \"\"\n",
            "  -- Installing: /tmp/tmpq7pj35f3/wheel/platlib/lib/libllava.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/tmpq7pj35f3/wheel/platlib/lib/libllava.so\" to \"\"\n",
            "  -- Installing: /tmp/tmpq7pj35f3/wheel/platlib/bin/llava-cli\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/tmpq7pj35f3/wheel/platlib/bin/llava-cli\" to \"\"\n",
            "  -- Installing: /tmp/tmpq7pj35f3/wheel/platlib/llama_cpp/libllava.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/tmpq7pj35f3/wheel/platlib/llama_cpp/libllava.so\" to \"\"\n",
            "  -- Installing: /tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/llama_cpp/libllava.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/pip-install-af5ihrzn/llama-cpp-python_e29e4621775845838176bb4585a54244/llama_cpp/libllava.so\" to \"\"\n",
            "  *** Making wheel...\n",
            "  *** Created llama_cpp_python-0.2.57-cp310-cp310-manylinux_2_35_x86_64.whl...\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.57-cp310-cp310-manylinux_2_35_x86_64.whl size=26394558 sha256=b4e94993b1ad70acb5eb9e6123113b8cb45c4954cae55797a0284b1e53137792\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-axv0pi05/wheels/7e/c0/00/e98d6e198f941c623da37b3f674354cbdccfcfb2cb9cf1133d\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: typing-extensions, numpy, MarkupSafe, diskcache, jinja2, llama-cpp-python\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.9.0\n",
            "    Uninstalling typing_extensions-4.9.0:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/__pycache__/typing_extensions.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/typing_extensions-4.9.0.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/typing_extensions.py\n",
            "      Successfully uninstalled typing_extensions-4.9.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Removing file or directory /usr/local/bin/f2py\n",
            "      Removing file or directory /usr/local/bin/f2py3\n",
            "      Removing file or directory /usr/local/bin/f2py3.10\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy-1.22.4.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy.libs/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy/\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  changing mode of /usr/local/bin/f2py to 755\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/MarkupSafe-2.1.5.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/markupsafe/\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: diskcache\n",
            "    Found existing installation: diskcache 5.6.3\n",
            "    Uninstalling diskcache-5.6.3:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/diskcache-5.6.3.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/diskcache/\n",
            "      Successfully uninstalled diskcache-5.6.3\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.3\n",
            "    Uninstalling Jinja2-3.1.3:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/Jinja2-3.1.3.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/jinja2/\n",
            "      Successfully uninstalled Jinja2-3.1.3\n",
            "  Attempting uninstall: llama-cpp-python\n",
            "    Found existing installation: llama_cpp_python 0.2.57\n",
            "    Uninstalling llama_cpp_python-0.2.57:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/bin/__pycache__/convert-lora-to-ggml.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/bin/__pycache__/convert.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/bin/convert-lora-to-ggml.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/bin/convert.py\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/bin/llava-cli\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/include/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/lib/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/llama_cpp/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/llama_cpp_python-0.2.57.dist-info/\n",
            "      Successfully uninstalled llama_cpp_python-0.2.57\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.16.0 which is incompatible.\n",
            "unstructured 0.12.6 requires typing-extensions==4.9.0, but you have typing-extensions 4.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 diskcache-5.6.3 jinja2-3.1.3 llama-cpp-python-0.2.57 numpy-1.26.4 typing-extensions-4.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import All the Required Libraries"
      ],
      "metadata": {
        "id": "d8Obx-wbsPbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import LlamaCpp\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from huggingface_hub import hf_hub_download\n",
        "from langchain.chains.question_answering import load_qa_chain"
      ],
      "metadata": {
        "id": "eWDsgqwFfjLl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks support token-wise streaming\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "# Verbose is required to pass to the callback manager"
      ],
      "metadata": {
        "id": "6IGdw0HUfjRB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Quantized Models from the Hugging Face Community"
      ],
      "metadata": {
        "id": "GASSH4KiuVWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Hugging Face community provides quantized models, which allow us to efficiently and effectively utilize the model on the T4 GPU. It is important to consult reliable sources before using any model.\n",
        "\n",
        "There are several variations available, but the ones that interest us are based on the GGLM library.\n",
        "\n",
        "We can see the different variations that Llama-2-13B-GGML has [here](https://huggingface.co/models?search=llama%202%20ggml).\n",
        "\n",
        "\n",
        "\n",
        "In this case, we will use the model called [Llama-2-13B-chat-GGML](https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML)."
      ],
      "metadata": {
        "id": "yB3z0JmNuZqo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Quantization reduces precision to optimize resource usage."
      ],
      "metadata": {
        "id": "_Byr1f3m7NMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantization is a technique to reduce the computational and memory costs of running inference by representing the weights and activations with low-precision data types like 8-bit integer ( int8 ) instead of the usual 32-bit floating point ( float32 )."
      ],
      "metadata": {
        "id": "M-SRSFdz72S6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGML\"\n",
        "# model_basename = \"llama-2-13b-chat.ggmlv3.q5_1.bin\" # the model is in bin format\n",
        "# model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)"
      ],
      "metadata": {
        "id": "nVK36nelfwL-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are not able to load the model in above ggml format but from github we have found that"
      ],
      "metadata": {
        "id": "EpuiCkKPlZs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eUGs5lPmjMQa",
        "outputId": "4f7483a7-193c-41e8-d964-bd9bfc85c3e9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = \"TheBloke/CodeLlama-13B-Python-GGUF\"\n",
        "model_basename = \"codellama-13b-python.Q5_K_M.gguf\"\n",
        "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "caca04f9aeb3497890dcb156e73ac071",
            "02ecffa91dfc49a09ceac96194746d3c",
            "6fdd2e07364e48e38078fdc10df0273c",
            "8da5653096a54114946a7e64465c1c27",
            "7d358a3b8ccd4507b6568c83a6c619c2",
            "0d18dc9723fa490f891404591324c467",
            "9cbea59a576a43dda004e209e4536147",
            "ccef05d3f9d34bb2b1439b3a181e5ac3",
            "ae7a384b860b45faa49fe9fa698b977d",
            "2906a44937a746b7b7d5b88a20a4acbc",
            "c6310166cb724e219ce95ecacad592f9"
          ]
        },
        "id": "KsnO4GcmkHcb",
        "outputId": "0da42811-7120-4179-b242-86fc184184df"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "codellama-13b-python.Q5_K_M.gguf:   0%|          | 0.00/9.23G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "caca04f9aeb3497890dcb156e73ac071"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_gpu_layers = 40  # Change this value based on your model and your GPU VRAM pool.\n",
        "n_batch = 256  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "\n",
        "# Loading model,\n",
        "llm = LlamaCpp(\n",
        "    model_path=model_path,\n",
        "    max_tokens=256,\n",
        "    n_gpu_layers=n_gpu_layers,\n",
        "    n_batch=n_batch,\n",
        "    callback_manager=callback_manager,\n",
        "    n_ctx=1024,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "tM3kTMKUfjT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "766e7a47-3e9d-492a-e192-cc8d45de59a7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 20 key-value pairs and 363 tensors from /root/.cache/huggingface/hub/models--TheBloke--CodeLlama-13B-Python-GGUF/snapshots/c9b66de0e0716d0515f4a86362fd64646a035df6/codellama-13b-python.Q5_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = codellama_codellama-13b-python-hf\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 16384\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 17\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   81 tensors\n",
            "llama_model_loader: - type q5_K:  241 tensors\n",
            "llama_model_loader: - type q6_K:   41 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 16384\n",
            "llm_load_print_meta: n_embd           = 5120\n",
            "llm_load_print_meta: n_head           = 40\n",
            "llm_load_print_meta: n_head_kv        = 40\n",
            "llm_load_print_meta: n_layer          = 40\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
            "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 13824\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 1000000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 16384\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 13B\n",
            "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
            "llm_load_print_meta: model params     = 13.02 B\n",
            "llm_load_print_meta: model size       = 8.60 GiB (5.67 BPW) \n",
            "llm_load_print_meta: general.name     = codellama_codellama-13b-python-hf\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.28 MiB\n",
            "llm_load_tensors: offloading 40 repeating layers to GPU\n",
            "llm_load_tensors: offloaded 40/41 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =  8801.63 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  8566.02 MiB\n",
            "....................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 1024\n",
            "llama_new_context_with_model: n_batch    = 256\n",
            "llama_new_context_with_model: n_ubatch   = 256\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =   800.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  800.00 MiB, K (f16):  400.00 MiB, V (f16):  400.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =    31.25 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   164.42 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =     6.00 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1324\n",
            "llama_new_context_with_model: graph splits = 4\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '16384', 'general.name': 'codellama_codellama-13b-python-hf', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '40', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '17'}\n",
            "Using fallback chat format: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain=load_qa_chain(llm, chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "npgS9EoYhA8m"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"what is the loss function of logistic regression?\"\n",
        "docs=docsearch.similarity_search(query, k=1)"
      ],
      "metadata": {
        "id": "ISwGOqhrhCfG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEhQ8Qs_kNDa",
        "outputId": "2f378ac6-6bad-4b61-febd-6b530515e26b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='For logistic regression, this loss function is conveniently convex . A convex func- convex\\ntion has at most one minimum; there are no local minima to get stuck in, so gradient\\ndescent starting from any point is guaranteed to ﬁnd the minimum. (By contrast,\\nthe loss for multi-layer neural networks is non-convex, and gradient descent may\\nget stuck in local minima for neural network training and never ﬁnd the global opti-\\nmum.)')]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "7d1OLGzzhDvw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "6f3765ee-3009-45ee-bd09-27184cdbe883"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the loss function of logistic regression is the negative negative negative negative negative negative negative negative negat-\n",
            "ive negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     694.10 ms\n",
            "llama_print_timings:      sample time =     142.13 ms /   256 runs   (    0.56 ms per token,  1801.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     767.46 ms /    17 tokens (   45.14 ms per token,    22.15 tokens per second)\n",
            "llama_print_timings:        eval time =   16032.77 ms /   255 runs   (   62.87 ms per token,    15.90 tokens per second)\n",
            "llama_print_timings:       total time =   18365.75 ms /   272 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' the loss function of logistic regression is the negative negative negative negative negative negative negative negative negat-\\nive negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"YOLOv7 trained on which dataset\"\n",
        "docs=docsearch.similarity_search(query)"
      ],
      "metadata": {
        "id": "XoVfiG-Yjcyv"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "za0WuBbkjc7A",
        "outputId": "a1c55d3d-4b1d-400b-9e49-24e709e2cade"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " YOLOv7 trained on the c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     694.10 ms\n",
            "llama_print_timings:      sample time =     146.28 ms /   256 runs   (    0.57 ms per token,  1750.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1059.16 ms /   396 tokens (    2.67 ms per token,   373.88 tokens per second)\n",
            "llama_print_timings:        eval time =   16610.58 ms /   255 runs   (   65.14 ms per token,    15.35 tokens per second)\n",
            "llama_print_timings:       total time =   19337.29 ms /   651 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' YOLOv7 trained on the c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 10: Query the Docs to get the Answer Back (Hugging Face Model)**"
      ],
      "metadata": {
        "id": "McjkimvGb9Me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceHub"
      ],
      "metadata": {
        "id": "N1ZKmRDZbsIc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":0.5, \"max_length\":512})"
      ],
      "metadata": {
        "id": "7aMLkSG_cEfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b85505c6-33c1-4e78-c015-ec4ea5241463"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.huggingface_hub.HuggingFaceHub` was deprecated in langchain-community 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain=load_qa_chain(llm, chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "F4e33CLGcKml"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"What are examples of good data science teams?\"\n",
        "docs=docsearch.similarity_search(query)"
      ],
      "metadata": {
        "id": "lNgpns06cb0I"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7sP_7PwlcfwV",
        "outputId": "a93a242c-49a8-4032-fc8b-6b743871fa79"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I don't know.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GoA5fiENfZjm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}